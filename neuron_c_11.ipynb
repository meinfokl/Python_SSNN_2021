{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7725393772125244, Accuracy: 31.488889694213867, Test Accuracy: 30.66132354736328\n",
      "[-0.37839627 -0.23019639  0.00235272  0.55321634  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 21, Loss: 1.526656150817871, Accuracy: 40.68888854980469, Test Accuracy: 38.6773567199707\n",
      "[ 0.30762318  0.00603966  0.00235272  0.69696915  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 41, Loss: 1.4855239391326904, Accuracy: 41.80000305175781, Test Accuracy: 39.078155517578125\n",
      "[ 0.5509553   0.00603966  0.00235272  0.6992117   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 61, Loss: 1.3864818811416626, Accuracy: 41.93333435058594, Test Accuracy: 39.8797607421875\n",
      "[ 0.6096995   0.00603966  0.00235272  0.72213703  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 81, Loss: 1.3515276908874512, Accuracy: 40.133331298828125, Test Accuracy: 37.87575149536133\n",
      "[ 0.6379628   0.00603966  0.00235272  0.71169585  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 101, Loss: 1.3322422504425049, Accuracy: 39.088890075683594, Test Accuracy: 37.474952697753906\n",
      "[ 0.64538753  0.00603966  0.00235272  0.68976474  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 121, Loss: 1.3192424774169922, Accuracy: 39.622222900390625, Test Accuracy: 37.07415008544922\n",
      "[ 0.6507228   0.00603966  0.00235272  0.67287743  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 141, Loss: 1.3103091716766357, Accuracy: 41.57777786254883, Test Accuracy: 39.27855682373047\n",
      "[ 0.65554184  0.00603966  0.00235272  0.6613038   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 161, Loss: 1.3040704727172852, Accuracy: 42.488887786865234, Test Accuracy: 40.08015823364258\n",
      "[ 0.6598303   0.00603966  0.00235272  0.65383494  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 181, Loss: 1.2995976209640503, Accuracy: 43.06666564941406, Test Accuracy: 41.28256607055664\n",
      "[ 0.66341764  0.00603966  0.00235272  0.6493364   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 201, Loss: 1.296279788017273, Accuracy: 43.911109924316406, Test Accuracy: 42.284568786621094\n",
      "[ 0.66625774  0.00603966  0.00235272  0.64692044  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 221, Loss: 1.3556426763534546, Accuracy: 44.844444274902344, Test Accuracy: 43.88777542114258\n",
      "[ 0.08901916  0.78857833  0.00235272  0.6618822   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 241, Loss: 1.3272002935409546, Accuracy: 45.400001525878906, Test Accuracy: 41.0821647644043\n",
      "[ 0.08901916  0.74106556  0.00235272  0.6718708   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 261, Loss: 1.314241647720337, Accuracy: 45.06666564941406, Test Accuracy: 41.0821647644043\n",
      "[ 0.08901916  0.7188385   0.00235272  0.6726815   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 281, Loss: 1.3065404891967773, Accuracy: 45.06666564941406, Test Accuracy: 41.482967376708984\n",
      "[ 0.08901916  0.70569444  0.00235272  0.6715284   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 301, Loss: 1.301343321800232, Accuracy: 45.244441986083984, Test Accuracy: 41.883766174316406\n",
      "[ 0.08901916  0.6976602   0.00235272  0.67052245  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 321, Loss: 1.2975589036941528, Accuracy: 45.488887786865234, Test Accuracy: 41.68336868286133\n",
      "[ 0.08901916  0.6925949   0.00235272  0.6701171   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 341, Loss: 1.2946542501449585, Accuracy: 45.42222213745117, Test Accuracy: 41.68336868286133\n",
      "[ 0.08901916  0.68925375  0.00235272  0.6703033   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 361, Loss: 1.2923340797424316, Accuracy: 45.53333282470703, Test Accuracy: 41.883766174316406\n",
      "[ 0.08901916  0.6869328   0.00235272  0.67097527  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 381, Loss: 1.2904200553894043, Accuracy: 45.488887786865234, Test Accuracy: 41.68336868286133\n",
      "[ 0.08901916  0.68523496  0.00235272  0.6720226   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 401, Loss: 1.2888022661209106, Accuracy: 45.266666412353516, Test Accuracy: 41.482967376708984\n",
      "[ 0.08901916  0.6839356   0.00235272  0.6733549   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 421, Loss: 1.2152503728866577, Accuracy: 48.266666412353516, Test Accuracy: 46.29258346557617\n",
      "[ 0.6030198   0.54094344  0.00235272  0.684604    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 441, Loss: 1.195642352104187, Accuracy: 49.088890075683594, Test Accuracy: 50.30060577392578\n",
      "[ 0.61360574  0.6114618   0.00235272  0.7009252   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 461, Loss: 1.1826815605163574, Accuracy: 52.64444351196289, Test Accuracy: 53.30661392211914\n",
      "[ 0.62832594  0.59774745  0.00235272  0.70607096  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 481, Loss: 1.1748037338256836, Accuracy: 53.91111373901367, Test Accuracy: 54.50901794433594\n",
      "[ 0.6315056   0.5746754   0.00235272  0.7061749   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 501, Loss: 1.1674121618270874, Accuracy: 54.86666488647461, Test Accuracy: 54.709415435791016\n",
      "[ 0.6303395   0.55820084  0.00235272  0.70541006  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 521, Loss: 1.1603648662567139, Accuracy: 55.66666793823242, Test Accuracy: 54.909820556640625\n",
      "[ 0.6279282   0.5495398   0.00235272  0.70449257  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 541, Loss: 1.1536520719528198, Accuracy: 56.42222213745117, Test Accuracy: 55.51102066040039\n",
      "[ 0.6250543   0.5447702   0.00235272  0.7034074   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 561, Loss: 1.1472285985946655, Accuracy: 56.95555877685547, Test Accuracy: 56.11222457885742\n",
      "[ 0.6220665   0.54207134  0.00235272  0.702193    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 581, Loss: 1.1410973072052002, Accuracy: 57.599998474121094, Test Accuracy: 56.513023376464844\n",
      "[ 0.6192496   0.5406487   0.00235272  0.7009151   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 601, Loss: 1.1353132724761963, Accuracy: 58.0444450378418, Test Accuracy: 56.513023376464844\n",
      "[ 0.61685306  0.540048    0.00235272  0.69958526  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 621, Loss: 1.1299337148666382, Accuracy: 58.64444351196289, Test Accuracy: 57.114227294921875\n",
      "[ 0.61509347  0.53992313  0.00235272  0.69817233  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 641, Loss: 1.1249746084213257, Accuracy: 58.88888931274414, Test Accuracy: 57.71543502807617\n",
      "[ 0.61416584  0.5399689   0.00235272  0.69663745  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 661, Loss: 1.1204062700271606, Accuracy: 59.15555191040039, Test Accuracy: 57.91583251953125\n",
      "[ 0.61427736  0.53988427  0.00235272  0.6949479   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 681, Loss: 1.1161630153656006, Accuracy: 58.88888931274414, Test Accuracy: 57.114227294921875\n",
      "[ 0.6156792   0.53932     0.00235272  0.69307613  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 701, Loss: 1.1121532917022705, Accuracy: 58.71111297607422, Test Accuracy: 56.71342468261719\n",
      "[ 0.61857945  0.5378478   0.00235272  0.6910045   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 721, Loss: 1.1082912683486938, Accuracy: 58.26667022705078, Test Accuracy: 56.312625885009766\n",
      "[ 0.6227364   0.53517747  0.00235272  0.6887597   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 741, Loss: 1.10456120967865, Accuracy: 57.95555877685547, Test Accuracy: 56.71342468261719\n",
      "[ 0.6270298   0.531742    0.00235272  0.6864695   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761, Loss: 1.101017951965332, Accuracy: 57.93333053588867, Test Accuracy: 56.11222457885742\n",
      "[ 0.630276    0.5284795   0.00235272  0.68432415  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 781, Loss: 1.0977141857147217, Accuracy: 57.666664123535156, Test Accuracy: 55.31061935424805\n",
      "[ 0.63217163  0.52582943  0.00235272  0.6824544   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 801, Loss: 1.0946637392044067, Accuracy: 57.55555725097656, Test Accuracy: 55.51102066040039\n",
      "[ 0.6328773   0.52375543  0.00235272  0.6809025   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 821, Loss: 1.0918554067611694, Accuracy: 57.355552673339844, Test Accuracy: 55.31061935424805\n",
      "[ 0.63255805  0.5221164   0.00235272  0.6796579   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 841, Loss: 1.089263677597046, Accuracy: 57.13333511352539, Test Accuracy: 54.308616638183594\n",
      "[ 0.6312929   0.5207877   0.00235272  0.67869276  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 861, Loss: 1.086859941482544, Accuracy: 56.82222366333008, Test Accuracy: 54.10821533203125\n",
      "[ 0.62908536  0.5196771   0.00235272  0.67797774  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 881, Loss: 1.084610104560852, Accuracy: 56.68888854980469, Test Accuracy: 53.30661392211914\n",
      "[ 0.6258689   0.518717    0.00235272  0.6774896   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 901, Loss: 1.0824824571609497, Accuracy: 56.57777786254883, Test Accuracy: 53.1062126159668\n",
      "[ 0.6214854   0.51785576  0.00235272  0.677216    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 921, Loss: 1.080435037612915, Accuracy: 56.5111083984375, Test Accuracy: 53.30661392211914\n",
      "[ 0.61564344  0.51705205  0.00235272  0.6771575   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 941, Loss: 1.0784173011779785, Accuracy: 56.37778091430664, Test Accuracy: 53.50701141357422\n",
      "[ 0.60784936  0.5162754   0.00235272  0.6773319   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 961, Loss: 1.0763487815856934, Accuracy: 56.13333511352539, Test Accuracy: 53.90781784057617\n",
      "[ 0.5973826   0.51551276  0.00235272  0.67778015  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 981, Loss: 1.0741127729415894, Accuracy: 55.977779388427734, Test Accuracy: 54.308616638183594\n",
      "[ 0.58357245  0.5148021   0.00235272  0.67856246  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1001, Loss: 1.0715943574905396, Accuracy: 55.977779388427734, Test Accuracy: 54.308616638183594\n",
      "[ 0.5669041   0.514284    0.00235272  0.67972815  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1021, Loss: 1.0688077211380005, Accuracy: 56.19999694824219, Test Accuracy: 54.308616638183594\n",
      "[ 0.5499204   0.51413137  0.00235272  0.6812457   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1041, Loss: 1.0659327507019043, Accuracy: 56.355552673339844, Test Accuracy: 54.50901794433594\n",
      "[ 0.5352244   0.5143506   0.00235272  0.68294907  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1061, Loss: 1.0631614923477173, Accuracy: 56.533329010009766, Test Accuracy: 54.50901794433594\n",
      "[ 0.5234367   0.51478785  0.00235272  0.6846019   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1081, Loss: 1.0606046915054321, Accuracy: 56.71111297607422, Test Accuracy: 54.10821533203125\n",
      "[ 0.5140453   0.5152888   0.00235272  0.68603057  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1101, Loss: 1.0582958459854126, Accuracy: 56.80000305175781, Test Accuracy: 52.705413818359375\n",
      "[ 0.50644195  0.51576227  0.00235272  0.68716246  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1121, Loss: 1.056226372718811, Accuracy: 56.66666793823242, Test Accuracy: 52.104209899902344\n",
      "[ 0.50016797  0.51616824  0.00235272  0.6879952   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1141, Loss: 1.0543705224990845, Accuracy: 56.19999694824219, Test Accuracy: 50.7014045715332\n",
      "[ 0.49489665  0.51649374  0.00235272  0.6885576   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1161, Loss: 1.0527007579803467, Accuracy: 55.62221908569336, Test Accuracy: 50.10020065307617\n",
      "[ 0.4903989   0.51674145  0.00235272  0.6888894   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1181, Loss: 1.0511881113052368, Accuracy: 55.088890075683594, Test Accuracy: 49.2985954284668\n",
      "[ 0.48650643  0.5169186   0.00235272  0.68902886  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1201, Loss: 1.0498111248016357, Accuracy: 54.73333740234375, Test Accuracy: 49.2985954284668\n",
      "[ 0.48309624  0.51703453  0.00235272  0.6890107   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1221, Loss: 1.0485504865646362, Accuracy: 54.622222900390625, Test Accuracy: 49.09819793701172\n",
      "[ 0.4800757   0.51709867  0.00235272  0.6888656   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1241, Loss: 1.0473889112472534, Accuracy: 54.4666633605957, Test Accuracy: 49.09819793701172\n",
      "[ 0.47737324  0.5171193   0.00235272  0.6886176   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1261, Loss: 1.0463149547576904, Accuracy: 54.377777099609375, Test Accuracy: 48.69739532470703\n",
      "[ 0.4749345   0.51710415  0.00235272  0.68828577  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1281, Loss: 1.0453177690505981, Accuracy: 54.377777099609375, Test Accuracy: 48.69739532470703\n",
      "[ 0.47271615  0.5170586   0.00235272  0.6878872   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1301, Loss: 1.0443875789642334, Accuracy: 54.333335876464844, Test Accuracy: 48.49699401855469\n",
      "[ 0.47068408  0.5169882   0.00235272  0.6874337   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1321, Loss: 1.0435174703598022, Accuracy: 54.333335876464844, Test Accuracy: 48.69739532470703\n",
      "[ 0.46881053  0.5168965   0.00235272  0.6869359   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1341, Loss: 1.042700171470642, Accuracy: 54.35555648803711, Test Accuracy: 48.296592712402344\n",
      "[ 0.46707317  0.51678824  0.00235272  0.68640167  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1361, Loss: 1.041930913925171, Accuracy: 54.35555648803711, Test Accuracy: 48.296592712402344\n",
      "[ 0.46545398  0.5166649   0.00235272  0.685837    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1381, Loss: 1.041204810142517, Accuracy: 54.377777099609375, Test Accuracy: 48.296592712402344\n",
      "[ 0.46393815  0.51652896  0.00235272  0.68524766  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1401, Loss: 1.0405174493789673, Accuracy: 54.377777099609375, Test Accuracy: 48.09619140625\n",
      "[ 0.4625131   0.5163825   0.00235272  0.6846385   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1421, Loss: 1.0398657321929932, Accuracy: 54.333335876464844, Test Accuracy: 47.89579391479492\n",
      "[ 0.46116787  0.5162278   0.00235272  0.6840116   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1441, Loss: 1.0392459630966187, Accuracy: 54.35555648803711, Test Accuracy: 48.09619140625\n",
      "[ 0.4598946   0.51606494  0.00235272  0.68337154  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1461, Loss: 1.0386552810668945, Accuracy: 54.35555648803711, Test Accuracy: 48.09619140625\n",
      "[ 0.45868525  0.51589566  0.00235272  0.682719    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1481, Loss: 1.0380911827087402, Accuracy: 54.400001525878906, Test Accuracy: 48.09619140625\n",
      "[ 0.4575338   0.5157211   0.00235272  0.6820574   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1501, Loss: 1.0375521183013916, Accuracy: 54.42222213745117, Test Accuracy: 48.09619140625\n",
      "[ 0.45643437  0.51554126  0.00235272  0.68138766  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1521, Loss: 1.037035584449768, Accuracy: 54.511112213134766, Test Accuracy: 48.296592712402344\n",
      "[ 0.45538306  0.5153574   0.00235272  0.6807117   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1541, Loss: 1.0365397930145264, Accuracy: 54.511112213134766, Test Accuracy: 48.69739532470703\n",
      "[ 0.45437458  0.5151691   0.00235272  0.68003005  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1561, Loss: 1.0360631942749023, Accuracy: 54.622222900390625, Test Accuracy: 49.09819793701172\n",
      "[ 0.45340654  0.51497823  0.00235272  0.6793448   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1581, Loss: 1.0356043577194214, Accuracy: 54.71110916137695, Test Accuracy: 49.09819793701172\n",
      "[ 0.45247495  0.5147847   0.00235272  0.6786554   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1601, Loss: 1.0351617336273193, Accuracy: 54.73333740234375, Test Accuracy: 49.2985954284668\n",
      "[ 0.45157745  0.51458806  0.00235272  0.67796415  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1621, Loss: 1.0347347259521484, Accuracy: 54.755558013916016, Test Accuracy: 49.2985954284668\n",
      "[ 0.45071116  0.5143892   0.00235272  0.6772706   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1641, Loss: 1.0343217849731445, Accuracy: 54.77777862548828, Test Accuracy: 49.2985954284668\n",
      "[ 0.44987464  0.5141889   0.00235272  0.6765754   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1661, Loss: 1.0339223146438599, Accuracy: 54.79999923706055, Test Accuracy: 49.2985954284668\n",
      "[ 0.4490657   0.513987    0.00235272  0.67587936  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1681, Loss: 1.0335350036621094, Accuracy: 54.77777862548828, Test Accuracy: 49.2985954284668\n",
      "[ 0.4482818   0.51378304  0.00235272  0.6751832   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1701, Loss: 1.0331590175628662, Accuracy: 54.77777862548828, Test Accuracy: 49.2985954284668\n",
      "[ 0.44752198  0.5135777   0.00235272  0.67448676  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1721, Loss: 1.0327948331832886, Accuracy: 54.77777862548828, Test Accuracy: 49.2985954284668\n",
      "[ 0.44678482  0.5133712   0.00235272  0.673791    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1741, Loss: 1.0324398279190063, Accuracy: 54.755558013916016, Test Accuracy: 49.2985954284668\n",
      "[ 0.44606853  0.513164    0.00235272  0.67309594  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1761, Loss: 1.032095193862915, Accuracy: 54.79999923706055, Test Accuracy: 49.499000549316406\n",
      "[ 0.44537288  0.51295596  0.00235272  0.6724027   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1781, Loss: 1.0317589044570923, Accuracy: 54.86666488647461, Test Accuracy: 49.499000549316406\n",
      "[ 0.4446955   0.51274705  0.00235272  0.6717096   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1801, Loss: 1.0314316749572754, Accuracy: 54.91111373901367, Test Accuracy: 49.499000549316406\n",
      "[ 0.44403633  0.5125375   0.00235272  0.67101794  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1821, Loss: 1.0311123132705688, Accuracy: 54.888885498046875, Test Accuracy: 49.699398040771484\n",
      "[ 0.44339383  0.51232743  0.00235272  0.670328    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1841, Loss: 1.0308005809783936, Accuracy: 54.86666488647461, Test Accuracy: 49.699398040771484\n",
      "[ 0.44276768  0.51211697  0.00235272  0.6696398   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1861, Loss: 1.030495524406433, Accuracy: 54.888885498046875, Test Accuracy: 49.699398040771484\n",
      "[ 0.44215637  0.5119059   0.00235272  0.66895264  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1881, Loss: 1.0301977396011353, Accuracy: 54.844444274902344, Test Accuracy: 49.699398040771484\n",
      "[ 0.44156027  0.51169497  0.00235272  0.66826934  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1901, Loss: 1.0299066305160522, Accuracy: 54.844444274902344, Test Accuracy: 49.699398040771484\n",
      "[ 0.4409777   0.51148397  0.00235272  0.6675888   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1921, Loss: 1.0296210050582886, Accuracy: 54.888885498046875, Test Accuracy: 49.699398040771484\n",
      "[ 0.44040874  0.5112722   0.00235272  0.6669097   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1941, Loss: 1.0293418169021606, Accuracy: 54.888885498046875, Test Accuracy: 49.699398040771484\n",
      "[ 0.43985197  0.5110615   0.00235272  0.6662336   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1961, Loss: 1.0290679931640625, Accuracy: 54.888885498046875, Test Accuracy: 49.699398040771484\n",
      "[ 0.43930736  0.5108506   0.00235272  0.6655614   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 1981, Loss: 1.0287997722625732, Accuracy: 54.93333435058594, Test Accuracy: 49.699398040771484\n",
      "[ 0.43877444  0.5106404   0.00235272  0.6648915   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2001, Loss: 1.0285357236862183, Accuracy: 55.0, Test Accuracy: 49.699398040771484\n",
      "[ 0.4382527   0.51042956  0.00235272  0.6642235   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2021, Loss: 1.0282772779464722, Accuracy: 55.022220611572266, Test Accuracy: 49.699398040771484\n",
      "[ 0.43774146  0.5102187   0.00235272  0.6635583   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2041, Loss: 1.02802312374115, Accuracy: 55.022220611572266, Test Accuracy: 49.699398040771484\n",
      "[ 0.4372404   0.51000816  0.00235272  0.6628973   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2061, Loss: 1.0277732610702515, Accuracy: 55.088890075683594, Test Accuracy: 49.699398040771484\n",
      "[ 0.4367493   0.50979835  0.00235272  0.6622379   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2081, Loss: 1.0275276899337769, Accuracy: 55.088890075683594, Test Accuracy: 49.699398040771484\n",
      "[ 0.4362675   0.50958836  0.00235272  0.6615814   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2101, Loss: 1.027286171913147, Accuracy: 55.088890075683594, Test Accuracy: 49.699398040771484\n",
      "[ 0.43579513  0.5093794   0.00235272  0.6609302   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2121, Loss: 1.0270485877990723, Accuracy: 55.088890075683594, Test Accuracy: 49.699398040771484\n",
      "[ 0.43533123  0.5091703   0.00235272  0.66027975  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2141, Loss: 1.0268144607543945, Accuracy: 55.088890075683594, Test Accuracy: 49.699398040771484\n",
      "[ 0.43487594  0.5089614   0.00235272  0.65963364  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2161, Loss: 1.0265837907791138, Accuracy: 55.11111068725586, Test Accuracy: 49.699398040771484\n",
      "[ 0.4344282   0.50875384  0.00235272  0.6589897   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2181, Loss: 1.0263570547103882, Accuracy: 55.133331298828125, Test Accuracy: 49.699398040771484\n",
      "[ 0.43398896  0.50854677  0.00235272  0.65835106  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2201, Loss: 1.0261335372924805, Accuracy: 55.11111068725586, Test Accuracy: 49.699398040771484\n",
      "[ 0.43355712  0.50834084  0.00235272  0.65771514  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2221, Loss: 1.0259132385253906, Accuracy: 55.11111068725586, Test Accuracy: 49.699398040771484\n",
      "[ 0.43313268  0.5081343   0.00235272  0.65708244  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2241, Loss: 1.02569580078125, Accuracy: 55.133331298828125, Test Accuracy: 49.699398040771484\n",
      "[ 0.43271515  0.50792885  0.00235272  0.65645427  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2261, Loss: 1.0254815816879272, Accuracy: 55.133331298828125, Test Accuracy: 49.699398040771484\n",
      "[ 0.43230423  0.5077239   0.00235272  0.65582895  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2281, Loss: 1.0252703428268433, Accuracy: 55.11111068725586, Test Accuracy: 49.699398040771484\n",
      "[ 0.43189982  0.5075199   0.00235272  0.655207    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2301, Loss: 1.0250613689422607, Accuracy: 55.133331298828125, Test Accuracy: 49.499000549316406\n",
      "[ 0.43150213  0.50731593  0.00235272  0.65458846  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2321, Loss: 1.024855613708496, Accuracy: 55.155555725097656, Test Accuracy: 49.499000549316406\n",
      "[ 0.43111125  0.5071128   0.00235272  0.65397245  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2341, Loss: 1.0246520042419434, Accuracy: 55.155555725097656, Test Accuracy: 49.499000549316406\n",
      "[ 0.43072578  0.506911    0.00235272  0.6533606   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2361, Loss: 1.0244512557983398, Accuracy: 55.155555725097656, Test Accuracy: 49.499000549316406\n",
      "[ 0.43034607  0.5067098   0.00235272  0.6527518   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2381, Loss: 1.0242526531219482, Accuracy: 55.17777633666992, Test Accuracy: 49.499000549316406\n",
      "[ 0.42997283  0.5065093   0.00235272  0.65214735  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2401, Loss: 1.024056315422058, Accuracy: 55.17777633666992, Test Accuracy: 49.499000549316406\n",
      "[ 0.42960545  0.5063094   0.00235272  0.6515458   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2421, Loss: 1.023862600326538, Accuracy: 55.17777633666992, Test Accuracy: 49.499000549316406\n",
      "[ 0.42924276  0.5061102   0.00235272  0.65094733  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2441, Loss: 1.0236704349517822, Accuracy: 55.17777633666992, Test Accuracy: 49.499000549316406\n",
      "[ 0.4288855   0.5059121   0.00235272  0.65035266  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2461, Loss: 1.023480772972107, Accuracy: 55.17777633666992, Test Accuracy: 49.499000549316406\n",
      "[ 0.42853317  0.5057145   0.00235272  0.6497607   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2481, Loss: 1.0232936143875122, Accuracy: 55.17777633666992, Test Accuracy: 49.499000549316406\n",
      "[ 0.42818612  0.50551677  0.00235272  0.6491728   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2501, Loss: 1.0231077671051025, Accuracy: 55.19999694824219, Test Accuracy: 49.499000549316406\n",
      "[ 0.42784357  0.50532085  0.00235272  0.6485896   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2521, Loss: 1.0229239463806152, Accuracy: 55.222225189208984, Test Accuracy: 49.499000549316406\n",
      "[ 0.42750612  0.50512546  0.00235272  0.6480082   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2541, Loss: 1.0227426290512085, Accuracy: 55.17777633666992, Test Accuracy: 49.699398040771484\n",
      "[ 0.42717353  0.5049309   0.00235272  0.64743054  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2561, Loss: 1.0225627422332764, Accuracy: 55.17777633666992, Test Accuracy: 49.699398040771484\n",
      "[ 0.4268452   0.50473714  0.00235272  0.6468561   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2581, Loss: 1.0223844051361084, Accuracy: 55.17777633666992, Test Accuracy: 49.699398040771484\n",
      "[ 0.426521    0.5045442   0.00235272  0.6462844   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2601, Loss: 1.0222079753875732, Accuracy: 55.19999694824219, Test Accuracy: 49.699398040771484\n",
      "[ 0.4262012   0.50435174  0.00235272  0.64571655  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2621, Loss: 1.0220332145690918, Accuracy: 55.19999694824219, Test Accuracy: 49.89979934692383\n",
      "[ 0.42588565  0.5041604   0.00235272  0.64515185  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2641, Loss: 1.0218604803085327, Accuracy: 55.19999694824219, Test Accuracy: 50.10020065307617\n",
      "[ 0.42557418  0.5039693   0.00235272  0.6445911   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2661, Loss: 1.0216889381408691, Accuracy: 55.19999694824219, Test Accuracy: 50.10020065307617\n",
      "[ 0.4252667   0.50377923  0.00235272  0.6440337   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2681, Loss: 1.0215189456939697, Accuracy: 55.19999694824219, Test Accuracy: 50.10020065307617\n",
      "[ 0.42496324  0.50359035  0.00235272  0.643478    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2701, Loss: 1.0213508605957031, Accuracy: 55.222225189208984, Test Accuracy: 50.10020065307617\n",
      "[ 0.42466363  0.50340235  0.00235272  0.64292616  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2721, Loss: 1.0211838483810425, Accuracy: 55.222225189208984, Test Accuracy: 50.10020065307617\n",
      "[ 0.42436823  0.503215    0.00235272  0.64237744  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2741, Loss: 1.021018624305725, Accuracy: 55.24444580078125, Test Accuracy: 50.10020065307617\n",
      "[ 0.42407644  0.50302863  0.00235272  0.6418329   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2761, Loss: 1.0208548307418823, Accuracy: 55.266666412353516, Test Accuracy: 50.10020065307617\n",
      "[ 0.42378816  0.5028429   0.00235272  0.6412915   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2781, Loss: 1.0206917524337769, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.42350426  0.50265783  0.00235272  0.6407529   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2801, Loss: 1.0205304622650146, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.42322353  0.5024731   0.00235272  0.6402174   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2821, Loss: 1.020370364189148, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.4229457   0.5022894   0.00235272  0.6396852   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2841, Loss: 1.0202118158340454, Accuracy: 55.266666412353516, Test Accuracy: 50.10020065307617\n",
      "[ 0.42267156  0.502107    0.00235272  0.63915604  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2861, Loss: 1.0200544595718384, Accuracy: 55.266666412353516, Test Accuracy: 50.10020065307617\n",
      "[ 0.4224004   0.5019255   0.00235272  0.6386303   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2881, Loss: 1.0198982954025269, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.42213276  0.50174487  0.00235272  0.63810766  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2901, Loss: 1.019743800163269, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.4218681   0.50156474  0.00235272  0.6375883   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2921, Loss: 1.0195894241333008, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.4216063   0.5013858   0.00235272  0.6370723   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2941, Loss: 1.0194365978240967, Accuracy: 55.28888702392578, Test Accuracy: 50.10020065307617\n",
      "[ 0.42134807  0.50120693  0.00235272  0.6365578   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2961, Loss: 1.0192850828170776, Accuracy: 55.35555648803711, Test Accuracy: 50.10020065307617\n",
      "[ 0.42109278  0.5010299   0.00235272  0.63604754  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 2981, Loss: 1.019134521484375, Accuracy: 55.377777099609375, Test Accuracy: 50.10020065307617\n",
      "[ 0.4208406   0.50085324  0.00235272  0.6355394   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3001, Loss: 1.018985390663147, Accuracy: 55.35555648803711, Test Accuracy: 50.10020065307617\n",
      "[ 0.42059115  0.500677    0.00235272  0.63503504  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3021, Loss: 1.0188367366790771, Accuracy: 55.35555648803711, Test Accuracy: 50.10020065307617\n",
      "[ 0.42034465  0.50050235  0.00235272  0.6345348   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3041, Loss: 1.0186893939971924, Accuracy: 55.35555648803711, Test Accuracy: 50.10020065307617\n",
      "[ 0.42010108  0.50032747  0.00235272  0.6340362   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3061, Loss: 1.0185433626174927, Accuracy: 55.35555648803711, Test Accuracy: 50.10020065307617\n",
      "[ 0.41986045  0.50015384  0.00235272  0.6335408   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3081, Loss: 1.0183976888656616, Accuracy: 55.35555648803711, Test Accuracy: 50.10020065307617\n",
      "[ 0.41962242  0.49998084  0.00235272  0.633048    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3101, Loss: 1.0182534456253052, Accuracy: 55.35555648803711, Test Accuracy: 50.30060577392578\n",
      "[ 0.41938683  0.49980873  0.00235272  0.63255847  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3121, Loss: 1.0181100368499756, Accuracy: 55.400001525878906, Test Accuracy: 50.30060577392578\n",
      "[ 0.4191545   0.49963778  0.00235272  0.63207334  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3141, Loss: 1.0179675817489624, Accuracy: 55.42222213745117, Test Accuracy: 50.30060577392578\n",
      "[ 0.41892424  0.4994678   0.00235272  0.63159096  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3161, Loss: 1.0178263187408447, Accuracy: 55.42222213745117, Test Accuracy: 50.30060577392578\n",
      "[ 0.418697    0.49929875  0.00235272  0.6311112   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3181, Loss: 1.017685890197754, Accuracy: 55.44444274902344, Test Accuracy: 50.30060577392578\n",
      "[ 0.41847265  0.4991297   0.00235272  0.63063407  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3201, Loss: 1.0175461769104004, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.41825098  0.4989611   0.00235272  0.6301604   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3221, Loss: 1.0174070596694946, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.41803157  0.49879366  0.00235272  0.62968934  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3241, Loss: 1.0172693729400635, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.4178149   0.49862725  0.00235272  0.6292218   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3261, Loss: 1.01713228225708, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41760075  0.49846062  0.00235272  0.62875545  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3281, Loss: 1.016995906829834, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41738874  0.49829537  0.00235272  0.62829256  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3301, Loss: 1.0168603658676147, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41717908  0.49813077  0.00235272  0.62783194  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3321, Loss: 1.0167254209518433, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41697145  0.49796706  0.00235272  0.6273737   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3341, Loss: 1.0165914297103882, Accuracy: 55.511112213134766, Test Accuracy: 50.500999450683594\n",
      "[ 0.41676643  0.49780422  0.00235272  0.62691885  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3361, Loss: 1.01645827293396, Accuracy: 55.511112213134766, Test Accuracy: 50.500999450683594\n",
      "[ 0.41656405  0.49764237  0.00235272  0.6264665   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3381, Loss: 1.0163257122039795, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41636366  0.49748132  0.00235272  0.6260177   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3401, Loss: 1.0161939859390259, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41616517  0.49732137  0.00235272  0.6255732   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3421, Loss: 1.0160627365112305, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41596925  0.4971619   0.00235272  0.62513125  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3441, Loss: 1.015932559967041, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.4157756   0.49700323  0.00235272  0.62469167  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3461, Loss: 1.0158030986785889, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.4155841   0.4968454   0.00235272  0.624254    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3481, Loss: 1.0156744718551636, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.4153949   0.49668828  0.00235272  0.6238193   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3501, Loss: 1.0155458450317383, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.4152085   0.49653143  0.00235272  0.62338704  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3521, Loss: 1.0154180526733398, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.4150238   0.4963749   0.00235272  0.6229577   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3541, Loss: 1.0152913331985474, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41484156  0.49621892  0.00235272  0.6225306   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3561, Loss: 1.0151644945144653, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41466126  0.496064    0.00235272  0.622106    0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3581, Loss: 1.0150389671325684, Accuracy: 55.511112213134766, Test Accuracy: 50.500999450683594\n",
      "[ 0.41448295  0.49590963  0.00235272  0.6216838   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3601, Loss: 1.0149139165878296, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41430715  0.49575627  0.00235272  0.62126535  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3621, Loss: 1.01478910446167, Accuracy: 55.4888916015625, Test Accuracy: 50.500999450683594\n",
      "[ 0.41413322  0.4956032   0.00235272  0.62084883  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3641, Loss: 1.0146652460098267, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.41396138  0.49545118  0.00235272  0.6204354   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3661, Loss: 1.014541745185852, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.41379175  0.4953      0.00235272  0.6200248   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3681, Loss: 1.0144188404083252, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.4136237   0.4951493   0.00235272  0.6196163   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3701, Loss: 1.014296293258667, Accuracy: 55.4888916015625, Test Accuracy: 50.30060577392578\n",
      "[ 0.41345766  0.49499896  0.00235272  0.6192108   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3721, Loss: 1.0141745805740356, Accuracy: 55.4888916015625, Test Accuracy: 50.30060577392578\n",
      "[ 0.4132939   0.4948496   0.00235272  0.61880785  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3741, Loss: 1.014053225517273, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.41313198  0.49470043  0.00235272  0.6184066   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3761, Loss: 1.013932466506958, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.41297174  0.49455234  0.00235272  0.6180082   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3781, Loss: 1.01381254196167, Accuracy: 55.44444274902344, Test Accuracy: 50.30060577392578\n",
      "[ 0.4128132   0.49440518  0.00235272  0.6176129   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3801, Loss: 1.0136926174163818, Accuracy: 55.44444274902344, Test Accuracy: 50.30060577392578\n",
      "[ 0.41265696  0.49425918  0.00235272  0.6172213   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3821, Loss: 1.0135736465454102, Accuracy: 55.4666633605957, Test Accuracy: 50.30060577392578\n",
      "[ 0.4125029   0.49411353  0.00235272  0.6168318   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3841, Loss: 1.0134549140930176, Accuracy: 55.44444274902344, Test Accuracy: 50.10020065307617\n",
      "[ 0.41235027  0.49396878  0.00235272  0.6164445   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3861, Loss: 1.0133370161056519, Accuracy: 55.4666633605957, Test Accuracy: 50.10020065307617\n",
      "[ 0.41219923  0.4938248   0.00235272  0.61605984  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3881, Loss: 1.0132193565368652, Accuracy: 55.4888916015625, Test Accuracy: 50.10020065307617\n",
      "[ 0.412051    0.49368086  0.00235272  0.61567783  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3901, Loss: 1.0131019353866577, Accuracy: 55.4666633605957, Test Accuracy: 50.10020065307617\n",
      "[ 0.4119047   0.4935378   0.00235272  0.6152981   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3921, Loss: 1.0129855871200562, Accuracy: 55.4888916015625, Test Accuracy: 50.10020065307617\n",
      "[ 0.41176     0.4933955   0.00235272  0.6149214   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3941, Loss: 1.0128694772720337, Accuracy: 55.4888916015625, Test Accuracy: 50.10020065307617\n",
      "[ 0.4116171   0.49325317  0.00235272  0.6145458   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3961, Loss: 1.0127533674240112, Accuracy: 55.4888916015625, Test Accuracy: 50.10020065307617\n",
      "[ 0.41147587  0.49311244  0.00235272  0.61417466  0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 3981, Loss: 1.0126383304595947, Accuracy: 55.4888916015625, Test Accuracy: 50.10020065307617\n",
      "[ 0.41133657  0.492972    0.00235272  0.6138054   0.08234973  0.436112\n",
      "  0.33039588  0.29468802 -0.8753699   0.16783257]\n",
      "Epoch 4000, Loss: 1.0125290155410767, Accuracy: 55.4888916015625, Test Accuracy: 50.10020065307617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2541e0d1978>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hybrid model L_S \n",
    "\n",
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import relu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LSLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,  num_outputs_s, num_outputs_r, num_outputs_l, activation=sigmoid, wstd = 0.3, bstd = 0.5):\n",
    "        super(LSLayer, self).__init__()\n",
    "        self.num_outputs_l = num_outputs_l\n",
    "        self.num_outputs_s = num_outputs_s \n",
    "        self.num_outputs_r = num_outputs_r\n",
    "        self.num_outputs = num_outputs_l + num_outputs_s + num_outputs_r\n",
    "        self.activation = activation\n",
    "        self.wstd = wstd\n",
    "        self.bstd = bstd\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.num_inputs = input_shape[-1]\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=(int(input_shape[-1]),\n",
    "                                             self.num_outputs), \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=self.wstd),\n",
    "                                     trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=self.bstd),\n",
    "                                   trainable=True)\n",
    "        \n",
    "    \n",
    "    # F2 method LS layer\n",
    "    def call(self, input):\n",
    "        \n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        kernel_S, kernel_L  = tf.split(self.kernel,[ self.num_outputs_s + self.num_outputs_r, self.num_outputs_l ], axis = 1 )\n",
    "        bias_S, bias_L  = tf.split(self.bias,[ self.num_outputs_s +  self.num_outputs_r, self.num_outputs_l ], axis = 0 )\n",
    "        \n",
    "        # case spherical\n",
    "        \n",
    "        s_shape  = self.num_outputs_s + self.num_outputs_r\n",
    "        In2 = tf.stack([In1] * s_shape)\n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([kernel_S] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(bias_S)\n",
    "        d_rR = tf.math.divide_no_nan(d_r,d_R)\n",
    "        d_x0 = tf.ones(d_rR.shape) - d_rR\n",
    "        result_S = tf.math.scalar_mul(6,d_x0)\n",
    "        result_S = sigmoid(result_S)\n",
    "        \n",
    "        # case linear\n",
    "\n",
    "        d_1 = tf.stack([bias_L] * isp[0])\n",
    "        result_L = tf.matmul(input, kernel_L) + d_1 \n",
    "        result_L = relu(result_L)\n",
    "\n",
    "        #case empty, merge\n",
    "        \n",
    "        if self.num_outputs_r > 0:\n",
    "            r_S, _ = tf.split (result_S,[self.num_outputs_s, self.num_outputs_r],axis=1 )\n",
    "            r_1 = np.zeros((result_S.shape[0],self.num_outputs_r))\n",
    "            result_R = tf.cast(tf.constant(r_1),tf.float32)\n",
    "            result = tf.concat([r_S, result_R, result_L],axis=1)            \n",
    "        else:\n",
    "            result = tf.concat([result_S, result_L],axis=1)        \n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "    def __init__(self,c,hs,hr,hl):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.d1 = LSLayer(hs,hr,hl)\n",
    "        self.d2 = Dense(c)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        #print (\"call benn:\",x, tf.math.reduce_sum(x))\n",
    "        return self.d2(x)\n",
    "        \n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    \n",
    "    predictions = model(datas, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "def update_NN_model (model, train_ds):\n",
    "\n",
    "    rdb = 0\n",
    "    odb = 0\n",
    "    N = min(2, model.d1.num_outputs_r)   # number of new SSN nodes\n",
    "    \n",
    "    if N <= 0:\n",
    "        return\n",
    "    \n",
    "    baditems = []\n",
    "    for datas, labels in train_ds:\n",
    "        predictions = model(datas, training=False)\n",
    "        for i in range(datas.shape[0]):\n",
    "            #print (datas.numpy()[i], predictions.numpy()[i], np.argmax(predictions.numpy()[i]), labels.numpy()[i],np.argmax(labels.numpy()[i]))\n",
    "            if np.argmax(predictions.numpy()[i]) != np.argmax(labels.numpy()[i]):\n",
    "                rdb = rdb + 1\n",
    "                baditems.append(datas.numpy()[i])\n",
    "            odb = odb + 1        \n",
    "    #print (\"pontossag:\",(odb-rdb)/odb, len(baditems))\n",
    "    inds = random.sample(range(len(baditems)), N)\n",
    "\n",
    "    neww = np.zeros((model.d1.num_inputs,N))\n",
    "    for i in range(N):\n",
    "        for j in range(model.d1.num_inputs):\n",
    "            neww[j,i] = baditems[inds[i]][j]\n",
    "\n",
    "    newb = np.zeros((N))\n",
    "    for i in range(N):\n",
    "        newb[i] = random.random()*model.d1.bstd\n",
    " \n",
    "    xu = model.d1.get_weights()\n",
    "    \n",
    "    for j in range(N):\n",
    "        for i in range(xu[0].shape[0]):\n",
    "            xu[0][i][model.d1.num_outputs_s + j] = neww[i,j]\n",
    "        xu[1][j] = newb[j]\n",
    "            \n",
    "    model.d1.set_weights(xu )\n",
    "    \n",
    "    model.d1.num_outputs_s = model.d1.num_outputs_s + N\n",
    "    model.d1.num_outputs_r = model.d1.num_outputs_r - N\n",
    "\n",
    "C= 6\n",
    "L= 50\n",
    "N= 5000\n",
    "M= 6\n",
    "HS = 4\n",
    "HR = 6\n",
    "HL = 0\n",
    "EPOCHS = 4000\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(C,HS,HR,HL)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "#print (x_train[:2])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "#print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "\n",
    "    if epoch > 1:\n",
    "        xu2 = model.d1.get_weights()\n",
    "        #print (\"WW\",epoch, \"WW\", xu2[0])\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for datas, labels in train_ds:\n",
    "        train_step(datas, labels)\n",
    "        \n",
    "                \n",
    "    for test_datas, test_labels in test_ds:\n",
    "        #print (\"test_data_shape\", test_datas.shape)\n",
    "        predictions = model(test_datas, training=False)\n",
    "        #print (\"ttttttttttttttttttt\")\n",
    "        #for i in range(test_datas.shape[0]):\n",
    "        #    print (predictions.numpy()[i], test_labels.numpy()[i])\n",
    "        test_step(test_datas, test_labels)\n",
    "        \n",
    "    if epoch % 200 == 3:\n",
    "        update_NN_model (model, train_ds)\n",
    "        \n",
    "        \n",
    "    X.append(epoch)\n",
    "    Y.append(test_accuracy.result() * 100)\n",
    "    if epoch % 20 == 0:\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "          )    \n",
    "        print(model.d1.bias.numpy())\n",
    "\n",
    "\n",
    "print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )    \n",
    "\n",
    "    \n",
    "plt.plot(X, Y,label=\"Accuracy curve\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.2 6.696599468718765\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\n",
    "x = [82,97,81,75,86,85,76,86,92,82]\n",
    "print (sum(x)/len(x), statistics.stdev(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
