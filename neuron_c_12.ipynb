{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7435534000396729, Accuracy: 23.533334732055664, Test Accuracy: 32.2645263671875\n",
      "update layer\n",
      "Epoch 20, Loss: 0.29485127329826355, Accuracy: 98.15555572509766, Test Accuracy: 98.99800109863281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20009003e10>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hybrid model L_S \n",
    "\n",
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import relu\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class LSLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,  num_outputs_s, num_outputs_r, num_outputs_l, activation=sigmoid, wstd = 0.3, bstd = 0.5):\n",
    "        super(LSLayer, self).__init__()\n",
    "        self.num_outputs_l = num_outputs_l\n",
    "        self.num_outputs_s = num_outputs_s \n",
    "        self.num_outputs_r = num_outputs_r\n",
    "        self.num_outputs = num_outputs_l + num_outputs_s + num_outputs_r\n",
    "        self.activation = activation\n",
    "        self.wstd = wstd\n",
    "        self.bstd = bstd\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.num_inputs = input_shape[-1]\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=(int(input_shape[-1]),\n",
    "                                             self.num_outputs), \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=self.wstd),\n",
    "                                     trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=self.bstd),\n",
    "                                   trainable=True)\n",
    "        \n",
    "    \n",
    "    # F2 method LS layer\n",
    "    def call(self, input):\n",
    "        \n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        kernel_S, kernel_L  = tf.split(self.kernel,[ self.num_outputs_s + self.num_outputs_r, self.num_outputs_l ], axis = 1 )\n",
    "        bias_S, bias_L  = tf.split(self.bias,[ self.num_outputs_s +  self.num_outputs_r, self.num_outputs_l ], axis = 0 )\n",
    "        \n",
    "        # case spherical\n",
    "        \n",
    "        s_shape  = self.num_outputs_s + self.num_outputs_r\n",
    "        In2 = tf.stack([In1] * s_shape)\n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([kernel_S] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(bias_S)\n",
    "        d_rR = tf.math.divide_no_nan(d_r,d_R)\n",
    "        d_x0 = tf.ones(d_rR.shape) - d_rR\n",
    "        result_S = tf.math.scalar_mul(6,d_x0)\n",
    "        result_S = sigmoid(result_S)\n",
    "        \n",
    "        # case linear\n",
    "\n",
    "        d_1 = tf.stack([bias_L] * isp[0])\n",
    "        result_L = tf.matmul(input, kernel_L) + d_1 \n",
    "        result_L = relu(result_L)\n",
    "\n",
    "        #case empty, merge\n",
    "        \n",
    "        '''\n",
    "        #print (self.num_outputs_r)\n",
    "        if self.num_outputs_r > 0:\n",
    "            r_S, _ = tf.split (result_S,[self.num_outputs_s, self.num_outputs_r],axis=1 )\n",
    "            r_1 = np.zeros((result_S.shape[0],self.num_outputs_r))\n",
    "            result_R = tf.cast(tf.constant(r_1),tf.float32)\n",
    "            result = tf.concat([r_S, result_R, result_L],axis=1)            \n",
    "            #print (self.num_outputs_s, self.num_outputs_r)\n",
    "            #print (\"result_S\", result_S)\n",
    "            #print (\"result_L\", result_L)\n",
    "            #print (\"result\", result)\n",
    "        else:\n",
    "            result = tf.concat([result_S, result_L],axis=1)        \n",
    "        '''\n",
    "        \n",
    "        result = tf.concat([result_S, result_L],axis=1)        \n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "    def __init__(self,c,hs,hr,hl):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.d1 = LSLayer(hs,hr,hl)\n",
    "        self.d2 = Dense(c)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        #print (\"call benn:\",x, tf.math.reduce_sum(x))\n",
    "        return self.d2(x)\n",
    "        \n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    \n",
    "    predictions = model(datas, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "def update_NN_model (model, train_ds,optimizer):\n",
    "\n",
    "    rdb = 0\n",
    "    odb = 0\n",
    "    #N = min(5, model.d1.num_outputs_r)   # number of new SSN nodes\n",
    "    N = model.d1.num_outputs_r   # number of new SSN nodes\n",
    "    \n",
    "    if N <= 0:\n",
    "        return\n",
    "    \n",
    "    # k-means\n",
    "    \n",
    "    baditems = []\n",
    "    for datas, labels in train_ds:\n",
    "        predictions = model(datas, training=False)\n",
    "        for i in range(datas.shape[0]):\n",
    "            #print (datas.numpy()[i], predictions.numpy()[i], np.argmax(predictions.numpy()[i]), labels.numpy()[i],np.argmax(labels.numpy()[i]))\n",
    "            if np.argmax(predictions.numpy()[i]) != np.argmax(labels.numpy()[i]):\n",
    "                rdb = rdb + 1\n",
    "                baditems.append(datas.numpy()[i])\n",
    "            odb = odb + 1        \n",
    "    #print (\"pontossag:\",(odb-rdb)/odb, len(baditems))\n",
    "    N = min(N, len(baditems))\n",
    "    if N == 0:\n",
    "        return\n",
    "    inds = random.sample(range(len(baditems)), N)\n",
    "    \n",
    "    print (\"update layer\")\n",
    "    #print (baditems)\n",
    "    centers = KMeans(n_clusters=N).fit(baditems).cluster_centers_\n",
    "    #print (\"centers:\")\n",
    "    #print (centers)\n",
    "    neww = np.zeros((model.d1.num_inputs,N))\n",
    "    for i in range(N):\n",
    "        for j in range(model.d1.num_inputs):\n",
    "            neww[j,i] = centers[i][j]\n",
    "    #print (\"neww\")\n",
    "    #print (neww)\n",
    "            \n",
    "    newb = np.zeros((N))\n",
    "    for i in range(N):\n",
    "        newb[i] = random.random()*model.d1.bstd\n",
    " \n",
    "    xu = model.d1.get_weights()\n",
    "    \n",
    "    for j in range(N):\n",
    "        for i in range(xu[0].shape[0]):\n",
    "            xu[0][i][model.d1.num_outputs_s + j] = neww[i,j]\n",
    "        xu[1][j] = newb[j]\n",
    "            \n",
    "    model.d1.set_weights(xu )\n",
    "    \n",
    "    model.d1.num_outputs_s = model.d1.num_outputs_s + N\n",
    "    model.d1.num_outputs_r = model.d1.num_outputs_r - N\n",
    "\n",
    "    #optimizer = tf.keras.optimizers.Adam\n",
    "    #for var in optimizer.variables():\n",
    "    #    var.assign(tf.zeros_like(var))\n",
    "    \n",
    "C= 6\n",
    "L= 50\n",
    "N= 5000\n",
    "M= 6\n",
    "HS = 45\n",
    "HR = 15\n",
    "HL = 0\n",
    "EPOCHS = 20\n",
    "Eupd = 6\n",
    "B = 32\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(C,HS,HR,HL)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "#print (x_train[:2])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(B)\n",
    "#print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(B)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "\n",
    "    if epoch > 1:\n",
    "        xu2 = model.d1.get_weights()\n",
    "        #print (\"WW\",epoch, \"WW\", xu2[0])\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for datas, labels in train_ds:\n",
    "        train_step(datas, labels)\n",
    "        \n",
    "                \n",
    "    for test_datas, test_labels in test_ds:\n",
    "        #print (\"test_data_shape\", test_datas.shape)\n",
    "        predictions = model(test_datas, training=False)\n",
    "        #print (\"ttttttttttttttttttt\")\n",
    "        #for i in range(test_datas.shape[0]):\n",
    "        #    print (predictions.numpy()[i], test_labels.numpy()[i])\n",
    "        test_step(test_datas, test_labels)\n",
    "        \n",
    "    if epoch == Eupd :\n",
    "        update_NN_model (model, train_ds, optimizer)\n",
    "        \n",
    "        \n",
    "    X.append(epoch)\n",
    "    Y.append(test_accuracy.result() * 100)\n",
    "    if epoch % 20 == 0:\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "          )    \n",
    "        #print(model.d1.bias.numpy())\n",
    "\n",
    "\n",
    "print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )    \n",
    "\n",
    "    \n",
    "plt.plot(X, Y,label=\"Accuracy curve\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.7 6.3604681868204915\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\n",
    "x = [100,86,91,81,96,97,88,86,93,99]\n",
    "print (sum(x)/len(x), statistics.stdev(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "print (3**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
