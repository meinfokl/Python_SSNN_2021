{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8427796  0.3063155  0.32259515 0.4594482 ]\n",
      " [0.4889703  0.39130405 0.32502672 0.83326495]]\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method SSLayer.call of <__main__.SSLayer object at 0x0000024C1F727D90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method SSLayer.call of <__main__.SSLayer object at 0x0000024C1F727D90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1, Loss: 2.553217887878418, Accuracy: 21.227779388427734, Test Accuracy: 31.515758514404297\n",
      "Epoch 2, Loss: 1.9791476726531982, Accuracy: 37.31111145019531, Test Accuracy: 49.924964904785156\n",
      "Epoch 3, Loss: 1.5717417001724243, Accuracy: 54.9555549621582, Test Accuracy: 66.33316802978516\n",
      "Epoch 4, Loss: 1.2295184135437012, Accuracy: 70.50555419921875, Test Accuracy: 74.98749542236328\n",
      "Epoch 5, Loss: 0.9582102298736572, Accuracy: 79.46111297607422, Test Accuracy: 82.29114532470703\n",
      "Epoch 6, Loss: 0.7580923438072205, Accuracy: 85.26111602783203, Test Accuracy: 87.79389953613281\n",
      "Epoch 7, Loss: 0.6085308790206909, Accuracy: 89.63888549804688, Test Accuracy: 92.44622802734375\n",
      "Epoch 8, Loss: 0.49339985847473145, Accuracy: 93.0888900756836, Test Accuracy: 93.8969497680664\n",
      "Epoch 9, Loss: 0.4034287631511688, Accuracy: 95.16666412353516, Test Accuracy: 94.94747161865234\n",
      "Epoch 10, Loss: 0.33369067311286926, Accuracy: 96.37222290039062, Test Accuracy: 95.99800109863281\n",
      "Epoch 11, Loss: 0.27968326210975647, Accuracy: 97.20555877685547, Test Accuracy: 96.74837493896484\n",
      "Epoch 12, Loss: 0.23754294216632843, Accuracy: 97.68333435058594, Test Accuracy: 97.54877471923828\n",
      "Epoch 13, Loss: 0.20373381674289703, Accuracy: 98.08333587646484, Test Accuracy: 97.8989486694336\n",
      "Epoch 14, Loss: 0.17603905498981476, Accuracy: 98.38333129882812, Test Accuracy: 97.948974609375\n",
      "Epoch 15, Loss: 0.15315119922161102, Accuracy: 98.62222290039062, Test Accuracy: 98.1990966796875\n",
      "Epoch 16, Loss: 0.13429470360279083, Accuracy: 98.73333740234375, Test Accuracy: 98.44922637939453\n",
      "Epoch 17, Loss: 0.11870016902685165, Accuracy: 98.8388900756836, Test Accuracy: 98.54927825927734\n",
      "Epoch 18, Loss: 0.10567568242549896, Accuracy: 98.9111099243164, Test Accuracy: 98.64932250976562\n",
      "Epoch 19, Loss: 0.09473101049661636, Accuracy: 99.0111083984375, Test Accuracy: 98.69934844970703\n",
      "Epoch 20, Loss: 0.08546611666679382, Accuracy: 99.07222747802734, Test Accuracy: 98.79940032958984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24c2821c2e0>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,  num_outputs,activation=sigmoid,wstd = 0.3, bstd = 0.5):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = activation\n",
    "        self.wstd = wstd\n",
    "        self.bstd = bstd\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=self.wstd))\n",
    "        #print (\"kernel \", self.kernel)\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=self.bstd))\n",
    "        \n",
    "        #print (\"bias \", self.bias)\n",
    "\n",
    "    \n",
    "    '''  \n",
    "    # F1 method\n",
    "    def call(self, input):\n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        In2 = tf.stack([In1] * self.kernel.shape[1]) \n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([self.kernel] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(self.bias)\n",
    "        d_r_R = d_R - d_r  \n",
    "        d_rR = tf.math.divide_no_nan(d_r_R,d_R)\n",
    "        d_x0 = tf.math.scalar_mul(3,d_rR)\n",
    "        d_x1 = tf.math.exp(d_x0)\n",
    "        d_x = d_r_R + d_x1 - tf.ones(d_x1.shape)         \n",
    "        result = self.activation(d_x)\n",
    "        return result\n",
    "    \n",
    "    '''    \n",
    "    # F2 method\n",
    "    def call(self, input):\n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        In2 = tf.stack([In1] * self.kernel.shape[1]) \n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([self.kernel] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(self.bias)\n",
    "        d_rR = tf.math.divide_no_nan(d_r,d_R)\n",
    "        d_x0 = tf.ones(d_rR.shape) - d_rR\n",
    "        d_x1 = tf.math.scalar_mul(6,d_x0)\n",
    "        result = self.activation(d_x1)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "  def __init__(self,c,l,n,m,h):\n",
    "    self.C=c\n",
    "    self.L=l\n",
    "    self.N=n\n",
    "    self.M=m\n",
    "    self.H = h\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.d1 = SSLayer(self.H)\n",
    "    self.d2 = Dense(self.C)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    #print (\"call benn:\",x, tf.math.reduce_sum(x))\n",
    "    return self.d2(x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    \n",
    "    predictions = model(datas, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "C= 20\n",
    "L= 100\n",
    "N= 20000\n",
    "M= 4\n",
    "H = 200\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(C,L,N,M,H)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "print (x_train[:2])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "#print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for datas, labels in train_ds:\n",
    "        train_step(datas, labels)\n",
    "\n",
    "    for test_datas, test_labels in test_ds:\n",
    "        #print (\"test_data_shape\", test_datas.shape)\n",
    "        predictions = model(test_datas, training=False)\n",
    "        #print (\"ttttttttttttttttttt\")\n",
    "        #for i in range(test_datas.shape[0]):\n",
    "            #print (predictions.numpy()[i], test_labels.numpy()[i])\n",
    "        test_step(test_datas, test_labels)\n",
    "    \n",
    "    X.append(epoch)\n",
    "    Y.append(test_accuracy.result() * 100)\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "      )    \n",
    "\n",
    "plt.plot(X, Y,label=\"Accuracy curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.0 0.9428090415820634\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\n",
    "x = [99,99,99,99,99,99]\n",
    "print (sum(x)/len(x), statistics.stdev(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
