{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8427796  0.3063155  0.32259515 0.4594482 ]\n",
      " [0.4889703  0.39130405 0.32502672 0.83326495]]\n",
      "Epoch 1, Loss: 2.3933231830596924, Accuracy: 25.799999237060547, Test Accuracy: 40.67033386230469\n",
      "Epoch 2, Loss: 1.6764274835586548, Accuracy: 51.92777633666992, Test Accuracy: 62.431217193603516\n",
      "Epoch 3, Loss: 1.2262535095214844, Accuracy: 69.18333435058594, Test Accuracy: 73.93696594238281\n",
      "Epoch 4, Loss: 0.9527133703231812, Accuracy: 76.7611083984375, Test Accuracy: 79.38969421386719\n",
      "Epoch 5, Loss: 0.7540768980979919, Accuracy: 84.01667022705078, Test Accuracy: 87.49374389648438\n",
      "Epoch 6, Loss: 0.6011888384819031, Accuracy: 89.04444885253906, Test Accuracy: 90.54527282714844\n",
      "Epoch 7, Loss: 0.48237985372543335, Accuracy: 91.60555267333984, Test Accuracy: 92.39620208740234\n",
      "Epoch 8, Loss: 0.3875524401664734, Accuracy: 93.77777862548828, Test Accuracy: 95.49774932861328\n",
      "Epoch 9, Loss: 0.31181859970092773, Accuracy: 95.79444885253906, Test Accuracy: 96.79840087890625\n",
      "Epoch 10, Loss: 0.2527063190937042, Accuracy: 97.03333282470703, Test Accuracy: 97.44872283935547\n",
      "Epoch 11, Loss: 0.20802941918373108, Accuracy: 97.62222290039062, Test Accuracy: 97.59880065917969\n",
      "Epoch 12, Loss: 0.17152616381645203, Accuracy: 97.92222595214844, Test Accuracy: 98.09904479980469\n",
      "Epoch 13, Loss: 0.14028622210025787, Accuracy: 98.31666564941406, Test Accuracy: 98.79940032958984\n",
      "Epoch 14, Loss: 0.11633177101612091, Accuracy: 98.86666870117188, Test Accuracy: 99.04953002929688\n",
      "Epoch 15, Loss: 0.09816296398639679, Accuracy: 99.1388931274414, Test Accuracy: 98.99949645996094\n",
      "Epoch 16, Loss: 0.08495308458805084, Accuracy: 99.18888854980469, Test Accuracy: 98.99949645996094\n",
      "Epoch 17, Loss: 0.07489098608493805, Accuracy: 99.2611083984375, Test Accuracy: 98.99949645996094\n",
      "Epoch 18, Loss: 0.06696672737598419, Accuracy: 99.30555725097656, Test Accuracy: 98.99949645996094\n",
      "Epoch 19, Loss: 0.06054877117276192, Accuracy: 99.33333587646484, Test Accuracy: 99.14957427978516\n",
      "Epoch 20, Loss: 0.055098846554756165, Accuracy: 99.35555267333984, Test Accuracy: 99.09955596923828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2367a9a19b0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import relu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,  num_outputs,activation=sigmoid,wstd = 0.3, bstd = 0.5):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = activation\n",
    "        self.wstd = wstd\n",
    "        self.bstd = bstd\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=self.wstd))\n",
    "        #print (\"kernel \", self.kernel)\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=self.bstd))\n",
    "        \n",
    "        #print (\"bias \", self.bias)\n",
    "\n",
    "    \n",
    "    '''  \n",
    "    # F1 method\n",
    "    def call(self, input):\n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        In2 = tf.stack([In1] * self.kernel.shape[1]) \n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([self.kernel] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(self.bias)\n",
    "        d_r_R = d_R - d_r  \n",
    "        d_rR = tf.math.divide_no_nan(d_r_R,d_R)\n",
    "        d_x0 = tf.math.scalar_mul(3,d_rR)\n",
    "        d_x1 = tf.math.exp(d_x0)\n",
    "        d_x = d_r_R + d_x1 - tf.ones(d_x1.shape)         \n",
    "        result = self.activation(d_x)\n",
    "        return result\n",
    "    \n",
    "    '''    \n",
    "    # F2 method\n",
    "    def call(self, input):\n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        In2 = tf.stack([In1] * self.kernel.shape[1]) \n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([self.kernel] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(self.bias)\n",
    "        d_rR = tf.math.divide_no_nan(d_r,d_R)\n",
    "        d_x0 = tf.ones(d_rR.shape) - d_rR\n",
    "        d_x1 = tf.math.scalar_mul(6,d_x0)\n",
    "        result = self.activation(d_x1)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "  def __init__(self,c,l,n,m,h):\n",
    "    self.C=c\n",
    "    self.L=l\n",
    "    self.N=n\n",
    "    self.M=m\n",
    "    self.H = h\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.d1 = SSLayer(self.H,activation=relu)\n",
    "    self.d2 = Dense(self.C)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    #print (\"call benn:\",x, tf.math.reduce_sum(x))\n",
    "    return self.d2(x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    \n",
    "    predictions = model(datas, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "C= 20\n",
    "L= 100\n",
    "N= 20000\n",
    "M= 4\n",
    "H = 200\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(C,L,N,M,H)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "print (x_train[:2])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "#print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for datas, labels in train_ds:\n",
    "        train_step(datas, labels)\n",
    "\n",
    "    for test_datas, test_labels in test_ds:\n",
    "        #print (\"test_data_shape\", test_datas.shape)\n",
    "        predictions = model(test_datas, training=False)\n",
    "        #print (\"ttttttttttttttttttt\")\n",
    "        #for i in range(test_datas.shape[0]):\n",
    "            #print (predictions.numpy()[i], test_labels.numpy()[i])\n",
    "        test_step(test_datas, test_labels)\n",
    "    \n",
    "    X.append(epoch)\n",
    "    Y.append(test_accuracy.result() * 100)\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "      )    \n",
    "\n",
    "plt.plot(X, Y,label=\"Accuracy curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.0 0.9428090415820634\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\n",
    "x = [99,99,99,99,99,99]\n",
    "print (sum(x)/len(x), statistics.stdev(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for datas, labels in train_ds:\n",
    "            predictions = model(datas, training=False)\n",
    "            for i in range(datas.shape[0]):\n",
    "                #print (datas.numpy()[i], predictions.numpy()[i], np.argmax(predictions.numpy()[i]), labels.numpy()[i],np.argmax(labels.numpy()[i]))\n",
    "                if np.argmax(predictions.numpy()[i]) != np.argmax(labels.numpy()[i]):\n",
    "                    rdb = rdb + 1\n",
    "                odb = odb + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
