{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 1401 155 465\n",
      "N= 1401\n",
      "k= 0 ------------------------------\n",
      "0 XX 0.61290324 0.6395349\n",
      "update layer\n",
      "10 XX 0.6797654 0.7383721\n",
      "20 XX 0.69431645 0.75581396\n",
      "30 XX 0.7161984 0.7732558\n",
      "40 XX 0.73453975 0.8023256\n",
      "accuracy: 0.8023256 0.8023256\n",
      "k= 1 ------------------------------\n",
      "0 XX 0.22580644 0.18023255\n",
      "update layer\n",
      "10 XX 0.65004885 0.7383721\n",
      "20 XX 0.6827445 0.7616279\n",
      "30 XX 0.7087756 0.75581396\n",
      "40 XX 0.7266195 0.7906977\n",
      "accuracy: 0.7906977 0.8023256\n",
      "k= 2 ------------------------------\n",
      "0 XX 0.5784946 0.6627907\n",
      "update layer\n",
      "10 XX 0.686217 0.7383721\n",
      "20 XX 0.7093702 0.76744187\n",
      "30 XX 0.73298645 0.79651165\n",
      "40 XX 0.7511146 0.8023256\n",
      "accuracy: 0.8023256 0.8023256\n",
      "k= 3 ------------------------------\n",
      "0 XX 0.4903226 0.55813956\n",
      "update layer\n",
      "10 XX 0.6656892 0.7383721\n",
      "20 XX 0.68858165 0.76744187\n",
      "30 XX 0.7130073 0.78488374\n",
      "40 XX 0.73574615 0.8197674\n",
      "accuracy: 0.8197674 0.8023256\n",
      "k= 4 ------------------------------\n",
      "0 XX 0.6860215 0.7383721\n",
      "update layer\n",
      "10 XX 0.7036168 0.75\n",
      "20 XX 0.73691756 0.7906977\n",
      "30 XX 0.76156783 0.8197674\n",
      "40 XX 0.7806976 0.8197674\n",
      "accuracy: 0.8197674 0.8197674\n",
      "k= 5 ------------------------------\n",
      "0 XX 0.6924731 0.7383721\n",
      "update layer\n",
      "10 XX 0.69442815 0.7383721\n",
      "20 XX 0.7190988 0.7732558\n",
      "30 XX 0.7376344 0.8197674\n",
      "40 XX 0.7553632 0.8255814\n",
      "accuracy: 0.8255814 0.8197674\n",
      "k= 6 ------------------------------\n",
      "0 XX 0.6903226 0.7383721\n",
      "update layer\n",
      "10 XX 0.6916911 0.7383721\n",
      "20 XX 0.7120328 0.7790698\n",
      "30 XX 0.7363857 0.81395346\n",
      "40 XX 0.75447154 0.8313953\n",
      "accuracy: 0.8313953 0.8197674\n",
      "k= 7 ------------------------------\n",
      "0 XX 0.12258065 0.11046512\n",
      "update layer\n",
      "10 XX 0.6780059 0.7383721\n",
      "20 XX 0.715617 0.75581396\n",
      "30 XX 0.7424211 0.75581396\n",
      "40 XX 0.762182 0.79651165\n",
      "accuracy: 0.79651165 0.8197674\n",
      "k= 8 ------------------------------\n",
      "0 XX 0.045161292 0.034883723\n",
      "update layer\n",
      "10 XX 0.598045 0.7383721\n",
      "20 XX 0.65560675 0.75\n",
      "30 XX 0.6930281 0.7732558\n",
      "40 XX 0.7166011 0.80813956\n",
      "accuracy: 0.80813956 0.8197674\n",
      "k= 9 ------------------------------\n",
      "0 XX 0.6967742 0.7383721\n",
      "update layer\n",
      "10 XX 0.70127076 0.7383721\n",
      "20 XX 0.7224782 0.78488374\n",
      "30 XX 0.7410337 0.79651165\n",
      "40 XX 0.7588775 0.81395346\n",
      "accuracy: 0.81395346 0.8197674\n",
      "final accuracy: 0.8197674\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hybrid model DLS my proposal\n",
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import relu\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "from pandas import  read_csv\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "#import statistics \n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "EPOCHS = 40+1\n",
    "#Eupd = [3,8,13,18,21,24,27]\n",
    "Eupd = [6]\n",
    "#Eupd = [20]\n",
    "es = 10\n",
    "\n",
    "#H = M * 5\n",
    "HS = 0\n",
    "HR = 20\n",
    "HL = 0\n",
    "\n",
    "B = 32\n",
    "A = 0.1\n",
    "\n",
    "(K, x_train,y_train,xA_val, yA_val, x_val,y_val, x_test,y_test) = read_data_array_cv2(\"Out_car.csv\")\n",
    "\n",
    "\n",
    "class LSLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,  num_outputs_s, num_outputs_r, num_outputs_l, indata,  Ara = 1.0, activation=sigmoid, wstd = 0.3, bstd = 0.5):\n",
    "        super(LSLayer, self).__init__()\n",
    "        self.num_outputs_l = num_outputs_l\n",
    "        self.num_outputs_s = num_outputs_s \n",
    "        self.num_outputs_r = num_outputs_r\n",
    "        self.num_outputs = num_outputs_l + num_outputs_s + num_outputs_r\n",
    "        self.activation = activation\n",
    "        self.wstd = wstd\n",
    "        self.bstd = bstd\n",
    "        self.traindata = indata\n",
    "        self.Ara = Ara\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.num_inputs = input_shape[-1]\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=(int(input_shape[-1]),\n",
    "                                             self.num_outputs), \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=self.wstd),\n",
    "                                     trainable=True)\n",
    "\n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=self.bstd),\n",
    "                                   trainable=True)\n",
    "            \n",
    "        #print ( \"set_circles ---------------------------\")\n",
    "        \n",
    "        M = self.num_outputs_s + self.num_outputs_r\n",
    "        \n",
    "        if M == 0:\n",
    "            return\n",
    "        \n",
    "        x_train =  self.traindata[0]\n",
    "        y_train =  self.traindata[1]\n",
    "        N = x_train.shape[0]   \n",
    "        D = x_train.shape[1]   \n",
    "        C = min (M*10,int(0.3*N))\n",
    "        #print (\"C\",C,\"M\",M)\n",
    "        \n",
    "        cls = KMeans(n_clusters=C).fit(x_train)\n",
    "        \n",
    "        centers = cls.cluster_centers_\n",
    "        #print (\"centers\", centers.shape)\n",
    "        #print (centers)\n",
    "        labels = cls.labels_\n",
    "\n",
    "        cvals = []\n",
    "        for c in range(C):\n",
    "            db1 = 0\n",
    "            db2 = 0\n",
    "            for i in range(N):\n",
    "                if labels[i] == c:\n",
    "                    if y_train[i][0] == 1:\n",
    "                        db1 += 1\n",
    "                    else:\n",
    "                        db2 += 1\n",
    "            try:\n",
    "                h = -math.log(db1/(db1+db2))*db1/(db1+db2) - math.log(db2/(db1+db2))*db2/(db1+db2) \n",
    "            except:\n",
    "                h = 0\n",
    "            #print (\"class:\", c,db1 + db2, db1, db2,h)\n",
    "            cvals.append((c,(db1+db2)* (1 - h)))\n",
    "\n",
    "        #print (cvals)\n",
    "        cvals.sort(key = lambda x: x[1] )\n",
    "        #print (cvals)\n",
    "\n",
    "        winc = []\n",
    "        #print (M)\n",
    "        for i in range(M):\n",
    "            cw = cvals[-i][0]\n",
    "            d0 = 0\n",
    "            for j in range(N):\n",
    "                if labels[j] == cw:\n",
    "                    d = math.sqrt(sum([ (centers[cw][k] - x_train[j][k])**2 for k in range(D) ]  ))\n",
    "                    if d > d0:\n",
    "                        d0 = d\n",
    "            winc.append((cw, centers[cw], d0 ) )\n",
    "\n",
    "        #for i in range(len(winc)):\n",
    "        #    print (i,  ':', winc[i])\n",
    "        #print (\"end -------------------------------\")\n",
    "\n",
    "        xu = self.get_weights()\n",
    "\n",
    "        #print (xu[0].shape, xu[1].shape)\n",
    "        \n",
    "        for c in range(D):\n",
    "            for m in range(M):\n",
    "                xu[0][c,m] = winc[m][1][c]\n",
    "        \n",
    "        \n",
    "        for m in range(M):\n",
    "            xu[1][m] = winc[m][2]* self.Ara\n",
    "            \n",
    "        #print (xu[0])\n",
    "        #print (xu[1])\n",
    "            \n",
    "        self.set_weights(xu )\n",
    "        #print (\"end ==============================\")\n",
    "        \n",
    "    \n",
    "    # F2 method LS layer\n",
    "    def call(self, input):\n",
    "        \n",
    "        #print (\"CALL :\", input.numpy())\n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        kernel_S, kernel_L  = tf.split(self.kernel,[ self.num_outputs_s + self.num_outputs_r, self.num_outputs_l ], axis = 1 )\n",
    "        bias_S, bias_L  = tf.split(self.bias,[ self.num_outputs_s +  self.num_outputs_r, self.num_outputs_l ], axis = 0 )\n",
    "        \n",
    "        # case spherical\n",
    "        \n",
    "        s_shape  = self.num_outputs_s + self.num_outputs_r\n",
    "        In2 = tf.stack([In1] * s_shape)\n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([kernel_S] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        result_S = relu(d_r)\n",
    "        \n",
    "        #d_R = tf.abs(bias_S)\n",
    "        #d_rR = tf.math.divide_no_nan(d_r,d_R)\n",
    "        #d_x0 = tf.ones(d_rR.shape) - d_rR\n",
    "        #result_S = tf.math.scalar_mul(6,d_x0)\n",
    "        #result_S = sigmoid(result_S)\n",
    "        #result_S = relu(result_S)\n",
    "        \n",
    "        # case linear\n",
    "\n",
    "        d_1 = tf.stack([bias_L] * isp[0])\n",
    "        result_L = tf.matmul(input, kernel_L) + d_1 \n",
    "        result_L = relu(result_L)\n",
    "\n",
    "                \n",
    "        result = tf.concat([result_S, result_L],axis=1)       \n",
    "        \n",
    "        '''\n",
    "        ra = result.numpy()\n",
    "        N = ra.shape[0]\n",
    "        M = ra.shape[1]\n",
    "        for n in range(N):\n",
    "            for m in range(3,M):\n",
    "                ra[n,m] = 0\n",
    "        result = tf.constant(ra)\n",
    "        '''\n",
    "        \n",
    "        return result\n",
    "    \n",
    "        \n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "    def __init__(self,c,hs,hr,hl,indata,A):\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.d1 = LSLayer(hs,hr,hl,indata,A)\n",
    "        self.d2 = Dense(c)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        #print (\"call benn:\",x, tf.math.reduce_sum(x))\n",
    "        return self.d2(x)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#@tf.function\n",
    "def train_step(datas, labels,modelk,loss_objectk,optimizerk,train_lossk,train_accuracyk):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = modelk(datas, training=True)\n",
    "        loss = loss_objectk(labels, predictions)\n",
    "    gradients = tape.gradient(loss, modelk.trainable_variables)\n",
    "    optimizerk.apply_gradients(zip(gradients, modelk.trainable_variables))\n",
    "\n",
    "    train_lossk(loss)\n",
    "    train_accuracyk(labels, predictions)\n",
    "\n",
    "#@tf.function\n",
    "def test_step(datas, labels,modelk,loss_objectk,test_lossk,test_accuracyk):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    \n",
    "    predictions = modelk(datas, training=False)\n",
    "    t_loss = loss_objectk(labels, predictions)\n",
    "\n",
    "    test_lossk(t_loss)\n",
    "    test_accuracyk(labels, predictions)\n",
    "        \n",
    "\n",
    "    \n",
    "def analyze_NN (model, train_ds, L=0,verbose = 0):\n",
    "    cnt = 0\n",
    "    xu = model.layers[L].get_weights()\n",
    "    C = xu[0].shape[1]\n",
    "    M = xu[0].shape[0]\n",
    "    C = model.d1.num_outputs_s + model.d1.num_outputs_r\n",
    "    #print (C,M)\n",
    "    Cvals = []\n",
    "    for c in range(C):\n",
    "        cnt = 0\n",
    "        outs = []\n",
    "        for datas, labels in train_ds:\n",
    "            dA = datas.numpy()\n",
    "            dL = labels.numpy()\n",
    "            for i in range(dA.shape[0]):\n",
    "                cnt += 1\n",
    "                cat = np.argmax(dL[i]) + 1\n",
    "                tA1 = tf.constant(dA[i])\n",
    "                tA = tf.reshape(tA1,[1,dA.shape[1]])\n",
    "                if L == 1:\n",
    "                    to1 = model.d1 (tA)\n",
    "                    to2 = model.d2 (to1)\n",
    "                else:\n",
    "                    to2 =  model.d1 (tA)\n",
    "                #print (tA.numpy())\n",
    "                #print (to2.numpy())\n",
    "                outs.append((to2[0][c].numpy(), cat))\n",
    "        #print (\"layer\", L, \" node\",  c, \" R=\",xu[1][c])\n",
    "        X = [x[0] for x in outs]\n",
    "        Y = [x[1] for x in outs]\n",
    "        X1 = [x[0] for x in outs if x[1] == 1]\n",
    "        X2 = [x[0] for x in outs if x[1] == 2]\n",
    "        sim_level = ks_2samp(X1,X2).pvalue\n",
    "        if verbose == 1:\n",
    "            plt.scatter(X,Y)\n",
    "            plt.show()\n",
    "            print (sim_level)\n",
    "        Cvals.append((c,sim_level))\n",
    "        \n",
    "    Cvals.sort(key = lambda x : -x[1])\n",
    "    return Cvals\n",
    "    \n",
    "    \n",
    "    \n",
    "def update_NN_model (model, train_ds ):\n",
    "\n",
    "    \n",
    "    rdb = 0\n",
    "    odb = 0\n",
    "    #N = min(5, model.d1.num_outputs_r)   # number of new SSN nodes\n",
    "    M = model.d1.num_outputs_r   # number of updated nodes\n",
    "    if M == 0:\n",
    "        return \n",
    "    \n",
    "    Clist = analyze_NN (model, train_ds)\n",
    "\n",
    "    baditems = []\n",
    "    yitems = []\n",
    "    for datas, labels in train_ds:\n",
    "        predictions = model(datas, training=False)\n",
    "        for i in range(datas.shape[0]):\n",
    "            #print (datas.numpy()[i], predictions.numpy()[i], np.argmax(predictions.numpy()[i]), labels.numpy()[i],np.argmax(labels.numpy()[i]))\n",
    "            if np.argmax(predictions.numpy()[i]) != np.argmax(labels.numpy()[i]):\n",
    "                rdb = rdb + 1\n",
    "                baditems.append(datas.numpy()[i])\n",
    "                yitems.append(labels.numpy()[i])\n",
    "            odb = odb + 1        \n",
    "\n",
    "    N = len(baditems)\n",
    "    C = min(2*M, len(baditems))  # number of cluster centers\n",
    "    if C == 0:\n",
    "        return\n",
    "    \n",
    "    print (\"update layer\")\n",
    "\n",
    "    # k-means\n",
    "\n",
    "    cls = KMeans(n_clusters=C).fit(baditems)\n",
    "        \n",
    "    centers = cls.cluster_centers_\n",
    "    labels = cls.labels_\n",
    "    D = centers.shape[1]\n",
    "\n",
    "    cvals = []\n",
    "    for c in range(C):\n",
    "        db1 = 0\n",
    "        db2 = 0\n",
    "        for i in range(N):\n",
    "            if labels[i] == c:\n",
    "                if yitems[i][0] == 1:\n",
    "                    db1 += 1\n",
    "                else:\n",
    "                    db2 += 1\n",
    "        try:\n",
    "            h = -math.log(db1/(db1+db2))*db1/(db1+db2) - math.log(db2/(db1+db2))*db2/(db1+db2) \n",
    "        except:\n",
    "            h = 0\n",
    "        #print (\"class:\", c,db1 + db2, db1, db2,h)\n",
    "        cvals.append((c,(db1+db2)* (1 - h)))\n",
    "\n",
    "    cvals.sort(key = lambda x: x[1] )\n",
    "\n",
    "    winc = []\n",
    "    #print (M)\n",
    "    for i in range(M):\n",
    "        cw = cvals[-i][0]\n",
    "        d0 = 0\n",
    "        for j in range(N):\n",
    "            if labels[j] == cw:\n",
    "                d = math.sqrt(sum([ (centers[cw][k] - baditems[j][k])**2 for k in range(D) ]  ))\n",
    "                if d > d0:\n",
    "                    d0 = d\n",
    "        winc.append((cw, centers[cw], d0 ) )\n",
    "\n",
    "    \n",
    "    xu = model.d1.get_weights()\n",
    "\n",
    "\n",
    "    for c in range(D):    # input dim\n",
    "        for m in range(M):   # neuron sorszam\n",
    "            nn = Clist[m][0]\n",
    "            xu[0][c,nn] = winc[m][1][c]\n",
    "\n",
    "\n",
    "    for m in range(M):\n",
    "        nn = Clist[m][0]\n",
    "        xu[1][nn] = winc[m][2]*model.d1.Ara\n",
    "\n",
    "    #print (xu[0])\n",
    "    #print (xu[1])\n",
    "\n",
    "    model.d1.set_weights(xu )\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# (x_train,y_train,x_test,y_test) = gen_data_array_cv(K)\n",
    "\n",
    "\n",
    "#K = 10\n",
    "\n",
    "M = x_train[0].shape[1]\n",
    "C = y_train[0].shape[1]\n",
    "\n",
    "model = []\n",
    "loss_object =  []\n",
    "optimizer = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "val_loss = []\n",
    "val_accuracy = []\n",
    "train_ds = []\n",
    "val_ds = []\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(B)\n",
    "\n",
    "\n",
    "gbest_v = 0\n",
    "gbest_t = 0\n",
    "\n",
    "ValA = []\n",
    "TestA = []\n",
    "ValAS = [0 for x in range(0,EPOCHS,es)]\n",
    "TestAS = [0 for x in range(0,EPOCHS,es)]\n",
    "X = [x for x in range(0,EPOCHS,es)]\n",
    "\n",
    "print (\"N=\", x_train[0].shape[0])\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "for k in range(K):\n",
    "    \n",
    "    best_v = 0\n",
    "    best_t = 0\n",
    "    print (\"k=\",k, \"------------------------------\")\n",
    "    # Create an instance of the model\n",
    "    model.append( NN_Model(C,HS,HR,HL,(x_train[k], y_train[k]),  A))\n",
    "    #model.append( NN_Model(H,C,0,0))\n",
    "\n",
    "    loss_object.append(tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "    #loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    #optimizer.append(tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,))\n",
    "    #optimizer.append(tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07,))\n",
    "    optimizer.append(tf.keras.optimizers.Adam())\n",
    "    train_loss.append(tf.keras.metrics.Mean(name='train_loss'))\n",
    "    train_accuracy.append(tf.keras.metrics.CategoricalAccuracy(name='train_accuracy'))\n",
    "\n",
    "    test_loss.append(tf.keras.metrics.Mean(name='test_loss'))\n",
    "    test_accuracy.append(tf.keras.metrics.CategoricalAccuracy(name='test_accuracy'))\n",
    "    \n",
    "    val_loss.append(tf.keras.metrics.Mean(name='val_loss'))\n",
    "    val_accuracy.append(tf.keras.metrics.CategoricalAccuracy(name='val_accuracy'))\n",
    "    \n",
    "\n",
    "    #print (x_train[:2])\n",
    "    train_ds.append( tf.data.Dataset.from_tensor_slices(\n",
    "        (x_train[k], y_train[k])).batch(B))\n",
    "    if K > 1:\n",
    "        val_ds.append( tf.data.Dataset.from_tensor_slices((x_val[k], y_val[k])).batch(B))\n",
    "        #val_ds.append( tf.data.Dataset.from_tensor_slices((xA_val[k], yA_val[k])).batch(B))\n",
    "        #print (train_ds)\n",
    "\n",
    "\n",
    "    ##set_circles(model[k],x_train[k], y_train[k], HS+HR)\n",
    "\n",
    "    e = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "      # Reset the metrics at the start of the next epoch\n",
    "\n",
    "        train_loss[k].reset_states()\n",
    "        train_accuracy[k].reset_states()\n",
    "        test_loss[k].reset_states()\n",
    "        test_accuracy[k].reset_states()\n",
    "        \n",
    "\n",
    "        for datas, labels in train_ds[k]:\n",
    "            train_step(datas, labels,model[k],loss_object[k],optimizer[k],train_loss[k],train_accuracy[k])\n",
    "\n",
    "\n",
    "        for test_datas, test_labels in test_ds:\n",
    "            #tpredictions = model[k](test_datas, training=False)\n",
    "            test_step(test_datas, test_labels,model[k],loss_object[k],test_loss[k],test_accuracy[k])\n",
    "\n",
    "        if K > 1:\n",
    "            for val_datas, val_labels in val_ds[k]:\n",
    "                #vpredictions = model[k](val_datas, training=False)\n",
    "                test_step(val_datas, val_labels,model[k],loss_object[k],val_loss[k],val_accuracy[k])\n",
    "            \n",
    "            \n",
    "        \n",
    "        #if (k == 0 or k == 8)  and epoch == 75:\n",
    "        #    analyze_NN(model[k], train_ds[k])\n",
    "    \n",
    "        if epoch in Eupd:\n",
    "            update_NN_model (model[k], train_ds[k])\n",
    "\n",
    "\n",
    "        if epoch % es == 0:\n",
    "            #print(\n",
    "            #    f'Epoch {epoch + 1}, '\n",
    "            #    f'Loss: {train_loss[k].result()}, '\n",
    "            #    f'Val Accuracy: {val_accuracy[k].result() * 100}, '\n",
    "            #    f'Test Accuracy: {test_accuracy[k].result() * 100}'\n",
    "            #  )    \n",
    "            if K > 1:\n",
    "                ValA.append(val_accuracy[k].result().numpy())\n",
    "                TestA.append(test_accuracy[k].result().numpy())\n",
    "                ValAS[e] += val_accuracy[k].result().numpy()/K\n",
    "                TestAS[e] += test_accuracy[k].result().numpy()/K\n",
    "                e += 1\n",
    "                if val_accuracy[k].result() > best_v :\n",
    "                    best_v = val_accuracy[k].result().numpy()\n",
    "                    best_t = test_accuracy[k].result().numpy()\n",
    "                    print(epoch, \"XX\", best_v,best_t)\n",
    "                else:\n",
    "                    print (epoch)\n",
    "                #print(model.d1.bias.numpy())\n",
    "            else:\n",
    "                print(epoch, \"XX\", test_accuracy[k].result().numpy())\n",
    "            \n",
    "\n",
    "    #print(\n",
    "    #    f'Epoch {epoch + 1}, '\n",
    "    #    f'Loss: {train_loss[k].result()}, '\n",
    "    #    f'Val Accuracy: {val_accuracy[k].result() * 100}, '\n",
    "    #    f'Test Accuracy: {test_accuracy[k].result() * 100}'\n",
    "    #  )    \n",
    "    #acclist.append(test_accuracy[k].result())\n",
    "    if best_v > gbest_v:\n",
    "        gbest_v = best_v\n",
    "        gbest_t = best_t\n",
    "        \n",
    "    print (\"accuracy:\",best_t, gbest_t)\n",
    "    #plt.plot(X, Y,label=\"Accuracy curve\")\n",
    "print (\"final accuracy:\",gbest_t)\n",
    "if K == 1:\n",
    "    print (\"final\",  test_accuracy[0].result().numpy())\n",
    "else:\n",
    "    plt.scatter(ValA,TestA)\n",
    "    plt.xlabel(\"validation accuracy\")\n",
    "    plt.ylabel(\"test accuracy\")\n",
    "    plt.show()\n",
    "    plt.plot(X,ValAS,label=\"validation accuracy\")\n",
    "    plt.plot(X,TestAS,label=\"test accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.575\n"
     ]
    }
   ],
   "source": [
    "x = [84.3,82,82,82]\n",
    "print (sum(x)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 1401 155 465\n",
      "k= 0\n",
      "0.72688174 0.7383721\n",
      "X [0.6962158460770884, 0.72688174] [0.6751918002616527, 0.7383721]\n",
      "0.78924733 0.79651165\n",
      "X [0.5238826099903353, 0.78924733] [0.512891969015432, 0.79651165]\n",
      "0.8129032 0.8255814\n",
      "X [0.42308147812402375, 0.8129032] [0.4143015860125076, 0.8255814]\n",
      "0.8516129 0.85465115\n",
      "X [0.360960554692053, 0.8516129] [0.3538901694985323, 0.85465115]\n",
      "k= 1\n",
      "0.744086 0.71511626\n",
      "0.77634406 0.75\n",
      "0.8301075 0.8023256\n",
      "0.8516129 0.84302324\n",
      "k= 2\n",
      "0.7354839 0.7267442\n",
      "0.78924733 0.80813956\n",
      "0.82150537 0.8313953\n",
      "0.84731185 0.8372093\n",
      "k= 3\n",
      "0.6989247 0.7093023\n",
      "0.7870968 0.75581396\n",
      "0.8172043 0.79651165\n",
      "0.8666667 0.8372093\n",
      "X [0.3758342437205776, 0.8666667] [0.3773809539717297, 0.8372093]\n",
      "k= 4\n",
      "0.7290323 0.7093023\n",
      "0.80215055 0.7732558\n",
      "0.83870965 0.81395346\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-487d0073447e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;31m#model.fit(x_train[k], y_train[k],  epochs=es,verbose = 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mres_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    435\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 10-fold coross validation \n",
    "# factory model\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "\n",
    "#K = 10\n",
    "\n",
    "#(x_train,y_train,x_test,y_test) = gen_data_array_cv(K)\n",
    "(K, x_train,y_train,xA_val, yA_val, x_val,y_val, x_test,y_test) = read_data_array_cv2(\"Out_car.csv\")\n",
    "\n",
    "H = 20\n",
    "E = 40\n",
    "es = 10\n",
    "\n",
    "best_v = 0\n",
    "best_t = 0\n",
    "\n",
    "ValA = []\n",
    "TestA = []\n",
    "ValAS = [0 for x in range(0,E,es)]\n",
    "TestAS = [0 for x in range(0,E,es)]\n",
    "X = [x for x in range(0,E,es)]\n",
    "\n",
    "for k in range(K):\n",
    "    print (\"k=\",k)\n",
    "    N = x_train[k].shape[0]\n",
    "    M = x_train[k].shape[1]\n",
    "    C = y_train[k].shape[1]\n",
    "\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(H, input_shape=(M,), activation='relu'),\n",
    "      tf.keras.layers.Dense(C)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['CategoricalAccuracy'])\n",
    "\n",
    "    #print (model.summary())\n",
    "    #print (x_val[k].shape,y_val[k].shape,)\n",
    "    #loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    for e in range(int(E/es)):\n",
    "        model.fit(x_train[k], y_train[k], validation_data=(x_val[k],y_val[k]), epochs=es,verbose = 0)\n",
    "        #model.fit(x_train[k], y_train[k],  epochs=es,verbose = 0)\n",
    "        res_test = model.evaluate(x_test,  y_test, verbose=0)\n",
    "        res_val = model.evaluate(x_val[k],  y_val[k], verbose=0)\n",
    "        print (res_val[1], res_test[1])\n",
    "        ValA.append(res_val[1])\n",
    "        TestA.append(res_test[1])\n",
    "        ValAS[e] += res_val[1]/K\n",
    "        TestAS[e] += res_test[1]/K\n",
    "        if res_val[1] > best_v:\n",
    "            best_v = res_val[1]\n",
    "            best_t = res_test[1]\n",
    "            print ('X', res_val, res_test)\n",
    "            \n",
    "print (\"acc=\", best_t, \"(\",best_v,\")\" )\n",
    "\n",
    "plt.scatter(ValA,TestA)\n",
    "#plt.xlim([0,1])\n",
    "#plt.ylim([0,1])\n",
    "plt.xlabel(\"validation accuracy\")\n",
    "plt.ylabel(\"test accuracy\")\n",
    "plt.show()\n",
    "plt.plot(X,ValAS,label=\"validation accuracy\")\n",
    "plt.plot(X,TestAS,label=\"test accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.11111111111111\n"
     ]
    }
   ],
   "source": [
    "x = [85,86,88,87,86.6,86,86,85,85.4]\n",
    "print (sum(x)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_array_cv2(fnev):\n",
    "    fin = open(fnev,\"r\")\n",
    "    sor = fin.read().split(\"\\n\")\n",
    "    sors = sor[0].split(\",\")\n",
    "    M = int(sors[0])\n",
    "    C = int(sors[1])\n",
    "    K = int(sors[2])\n",
    "    Nte = 0\n",
    "    Ntrt = 0\n",
    "    Ntrv = 0\n",
    "    Ntrv2 = 0\n",
    "    i = 0\n",
    "    while (sor[i+2][0:3] != \"Tra\"):\n",
    "        i += 1\n",
    "    Nte = i\n",
    "    i = 0\n",
    "    while (sor[i+3+Nte][0:3] != \"Val\"):\n",
    "        i += 1\n",
    "    Ntrt = i\n",
    "    i = 0\n",
    "    while (sor[i+4+Nte+Ntrt][0:3] != \"Val\"):\n",
    "        i += 1\n",
    "    Ntrv2 = i\n",
    "    i = 0\n",
    "    while (sor[i+5+Nte+Ntrt+Ntrv2][0:3] != \"Tra\"):\n",
    "        i += 1\n",
    "    Ntrv = i\n",
    "    \n",
    "    print (Nte, Ntrt, Ntrv, Ntrv2)\n",
    "    x2_test = np.zeros((Nte,M),dtype='float32')\n",
    "    y2_test = np.zeros((Nte,C))\n",
    "    \n",
    "    for i in range(2,2+Nte):\n",
    "        sors = sor[i].split(\",\")\n",
    "        for j in  range(M):\n",
    "            x2_test[i-2,j] = float(sors[j])\n",
    "        for j in  range(C):\n",
    "            y2_test[i-2,j] = float(sors[M+j])\n",
    "    \n",
    "    \n",
    "    x2_train = []\n",
    "    y2_train = []\n",
    "    x2_val = []\n",
    "    y2_val = []\n",
    "    x2A_val = []\n",
    "    y2A_val = []\n",
    "\n",
    "    for k in range(K):\n",
    "    \n",
    "        x2_train.append(np.zeros((Ntrt,M),dtype='float32'))\n",
    "        y2_train.append(np.zeros((Ntrt,C)))\n",
    "        x2_val.append(np.zeros((Ntrv2,M),dtype='float32'))\n",
    "        y2_val.append(np.zeros((Ntrv2,C)))\n",
    "        x2A_val.append(np.zeros((Ntrv,M),dtype='float32'))\n",
    "        y2A_val.append(np.zeros((Ntrv,C)))\n",
    "        \n",
    "        base = 2+Nte +  k*(Ntrt+1 + Ntrv2+1+Ntrv+1) +1\n",
    "        p = 0\n",
    "        for i in range( base, base + Ntrt ):\n",
    "            sors = sor[i].split(\",\")\n",
    "            for j in  range(M):\n",
    "                x2_train[k][p,j] = float(sors[j])\n",
    "            for j in  range(C):\n",
    "                y2_train[k][p,j] = float(sors[M+j])\n",
    "            p += 1\n",
    "        \n",
    "        base = base + (Ntrt + 1)\n",
    "        p = 0\n",
    "        for i in range(base, base + Ntrv2 ):\n",
    "            sors = sor[i].split(\",\")\n",
    "            for j in  range(M):\n",
    "                x2_val[k][p,j] = float(sors[j])\n",
    "            for j in  range(C):\n",
    "                y2_val[k][p,j] = float(sors[M+j])\n",
    "            p += 1\n",
    "            \n",
    "        base = base + (Ntrv2 + 1)\n",
    "        p = 0\n",
    "        for i in range(base, base + Ntrv ):\n",
    "            sors = sor[i].split(\",\")\n",
    "            for j in  range(M):\n",
    "                x2A_val[k][p,j] = float(sors[j])\n",
    "            for j in  range(C):\n",
    "                y2A_val[k][p,j] = float(sors[M+j])\n",
    "            p += 1\n",
    "        \n",
    "\n",
    "    fin.close()\n",
    "    \n",
    "    return (K, x2_train,y2_train, x2A_val, y2A_val, x2_val, y2_val, x2_test, y2_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
