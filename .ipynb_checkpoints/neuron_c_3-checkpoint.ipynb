{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sphere-Plane NN model\n",
    "## https://www.adeveloperdiary.com/data-science/machine-learning/understand-and-implement-the-backpropagation-algorithm-from-scratch-in-python/\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from math import exp\n",
    "from math import sqrt\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import randint\n",
    "import matplotlib.lines as lines \n",
    "\n",
    "import math\n",
    " \n",
    "# Initialize a network\n",
    "\n",
    "\n",
    "class neuron_s():\n",
    "    \n",
    "    def __init__(self, n_inputs,c,o):\n",
    "        self.mode = \"C\"\n",
    "        self.outlayer = o\n",
    "        self.inputs = [0 for _ in range(n_inputs)]\n",
    "        self.weights = [random() for _ in range(n_inputs)]\n",
    "\n",
    "        self.delta = 0\n",
    "        self.output = 0\n",
    "        self.R = .1 + 0.6*random()\n",
    "        self.C = c\n",
    "        self.al = 0.1\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dR = 0\n",
    "        \n",
    "    def copy (self):\n",
    "        new_neuron = neuron_s(len(self.inputs), self.C, self.outlayer)\n",
    "        new_neuron.inputs = self.inputs.copy()\n",
    "        new_neuron.weights = self.weights.copy()\n",
    "        new_neuron.delta = self.delta\n",
    "        new_neuron.output = self.output\n",
    "        new_neuron.R = self.R\n",
    "        return new_neuron\n",
    "    \n",
    "    def activate(self):\n",
    "        N = len(self.weights)\n",
    "        y1 = sum([self.inputs[i]* self.inputs[i] for i in range(N) ])\n",
    "        y2 = sum([self.inputs[i]* self.weights[i] for i in range(N) ])\n",
    "        y3 = sum([self.weights[i]* self.weights[i] for i in range(N) ])\n",
    " \n",
    "        activation = 1 - (y3 -  2*y2 + y1 )/(self.R**2)\n",
    "        return activation\n",
    "        \n",
    "    def transfer_l(self,activation):\n",
    "        self.output = activation\n",
    "        return self.output\n",
    "    \n",
    "    def transfer_derivative_l(self):\n",
    "        return 1\n",
    "    \n",
    "    def transfer(self,activation):\n",
    "        \n",
    "        if  -self.al*activation > 100:\n",
    "            self.output = 0\n",
    "        else:\n",
    "            self.output = 1.0 / (1.0 + exp(-self.al*activation)) \n",
    "        return self.output\n",
    "    \n",
    "    def transfer_derivative(self):\n",
    "        return self.al*self.output * (1.0 - self.output)\n",
    "\n",
    "    # Calculate the derivative of the activation function\n",
    "    def activation_derivate_by_input(self, idx):\n",
    "        return 2*(self.weights[idx]-self.inputs[idx])/(self.R**2)\n",
    "\n",
    "    def activation_derivate_by_weight(self, idx):\n",
    "        return 2*(-self.weights[idx]+self.inputs[idx])/(self.R**2)\n",
    "\n",
    "    def activation_derivate_by_R(self):\n",
    "        N = len(self.weights)\n",
    "        y1 = sum([self.inputs[i]* self.inputs[i] for i in range(N) ])\n",
    "        y2 = sum([self.inputs[i]* self.weights[i] for i in range(N) ])\n",
    "        y3 = sum([self.weights[i]* self.weights[i] for i in range(N) ])\n",
    "        return 2*(y3 - 2*y2 +y1)  / (self.R**3) \n",
    "    \n",
    "    def print_neuron_param(self):\n",
    "        print(self.weights, self.R,self.C)\n",
    "        \n",
    "    def calculate_update(self, Ct, m_st):\n",
    "        if self.output < .5 and self.C != Ct:\n",
    "            return\n",
    "        \n",
    "        if self.output < .5 and  m_st+0.01 < self.R :\n",
    "            return\n",
    "        \n",
    "        for j in range(len(self.weights)):\n",
    "            self.dw[j] += ( self.delta * self.activation_derivate_by_weight(j))\n",
    "        self.dR += self.delta*self.activation_derivate_by_R()\n",
    "        #print(self.C,self.delta, self.activation_derivate_by_R(), self.delta*self.activation_derivate_by_R())\n",
    "        \n",
    "\n",
    "    def update_weights(self, l_rate):\n",
    "        #print (\"update weights\")\n",
    "        \n",
    "        dH = sqrt(sum([x**2 for x in self.dw]) + self.dR**2 )*.5\n",
    "        if dH < 0.000001:\n",
    "            dH = 1\n",
    "\n",
    "        #print (\"update :\", self.inputs)\n",
    "        for j in range(len(self.weights)):\n",
    "            #print (\"   \", self.weights[j],self.dw[j]/dH ,\" == > \" ,self.weights[j] + l_rate * self.dw[j]/dH)\n",
    "            self.weights[j] += l_rate * self.dw[j]/dH\n",
    "            \n",
    "        #print (\"   \", self.R,self.dR/dH,\" == > \" ,self.R + l_rate * self.dR/dH)\n",
    "        self.R += l_rate * self.dR/dH\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dR = 0\n",
    "        \n",
    "    def draw_neuron(self, axes, plt):\n",
    "        cl = 'blue' if self.C > 0 else 'red'\n",
    "        cc = plt.Circle( (self.weights[0], self.weights[1] ), self.R ,fill = False,color=cl )   \n",
    "        axes.add_artist( cc)    \n",
    "        \n",
    "        \n",
    "class neuron_l():\n",
    "    \n",
    "    def __init__(self, n_inputs,o):\n",
    "        self.mode = \"L\"\n",
    "        self.outlayer = o\n",
    "        self.inputs = [0 for _ in range(n_inputs)]\n",
    "        self.weights = [random() for _ in range(n_inputs)]\n",
    "        self.delta = 0\n",
    "        self.output = 0\n",
    "        self.A = random()\n",
    "        \n",
    "    def copy (self):\n",
    "        new_neuron = neuron_s(len(self.inputs),  self.outlayer)\n",
    "        new_neuron.inputs = self.inputs.copy()\n",
    "        new_neuron.weights = self.weights.copy()\n",
    "        new_neuron.delta = self.delta\n",
    "        new_neuron.output = self.output\n",
    "        new_neuron.A = self.A\n",
    "        return new_neuron\n",
    "\n",
    "    def activate(self):\n",
    "        N = len(self.weights)\n",
    "        y1 = sum([self.inputs[i]* self.weights[i] for i in range(N) ])\n",
    "        activation = (y1  + self.A) \n",
    "        return activation\n",
    "    \n",
    "    def transfer(self,activation):\n",
    "        self.output = 1.0 / (1.0 + exp(-activation)) \n",
    "        return self.output\n",
    "\n",
    "    def transfer_derivative(self):\n",
    "        return self.output * (1.0 - self.output)\n",
    "\n",
    "    # Calculate the derivative of the activation function\n",
    "    def activation_derivate_by_input(self, idx):\n",
    "        return self.weights[idx]\n",
    "\n",
    "    def activation_derivate_by_weight(self, idx):\n",
    "        return  self.inputs[idx]\n",
    "\n",
    "    def activation_derivate_by_A(self):\n",
    "        return 1\n",
    "    \n",
    "    def print_neuron_param(self):\n",
    "        print(self.weights, self.A)\n",
    "\n",
    "    def update_weights(self, l_rate):\n",
    "        for j in range(len(self.weights)):\n",
    "            self.weights[j] += l_rate * self.delta * self.activation_derivate_by_weight(j)\n",
    "        self.A += l_rate * self.delta*self.activation_derivate_by_A()\n",
    "\n",
    "    def draw_neuron(self, axes, plt):\n",
    "        cl = 'black\"'\n",
    "        x1 = -2\n",
    "        y1 = (self.A - self.weights[0]*x1) / self.weights[1]\n",
    "        x2 = 8\n",
    "        y2 = (self.A - self.weights[0]*x2) / self.weights[1]\n",
    "        line   = plt.Line2D([x1,x2],[y1,y2],mfc ='green')\n",
    "        #print (\"line\",[x1,x2],[y1,y2],\"w\",self.weights)\n",
    "        plt.gca().add_line(line)    \n",
    "        \n",
    "        \n",
    "class SSNN_network():\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.layers = []\n",
    "        self.outputs = None\n",
    "        self.HL = 0\n",
    "        self.OL = 0\n",
    "\n",
    "    def init (self, n_inputs, hidden_nmode, outputs_nmode, outputs_category):\n",
    "        self.layers = []\n",
    "        n_outputs = len(outputs_nmode)\n",
    "        n_hiddens = len(hidden_nmode)\n",
    "        self.outputs = outputs_category\n",
    "        self.HL = -1\n",
    "        self.OL = 0\n",
    "        self.layers.append([])\n",
    "        if n_hiddens > 0:\n",
    "            self.layers.append([])\n",
    "            self.HL = 0\n",
    "            self.OL = 1\n",
    "            for i in range(n_hiddens):\n",
    "                if hidden_nmode[i] == 'S': \n",
    "                    self.layers[self.HL].append(neuron_s(n_inputs,0,False))\n",
    "                else:\n",
    "                    self.layers[self.HL].append(neuron_l(n_inputs,False))\n",
    "            for i in range(n_outputs):\n",
    "                if outputs_nmode[i] == 'S': \n",
    "                    self.layers[self.OL].append(neuron_s(n_hiddens,outputs_category[i],True))\n",
    "                else:\n",
    "                    self.layers[self.OL].append(neuron_l(n_hiddens,True))\n",
    "        else:\n",
    "            for i in range(n_outputs):\n",
    "                if outputs_nmode[i] == 'S':\n",
    "                    self.layers[self.OL].append(neuron_s(n_inputs,outputs_category[i],True))\n",
    "                else:\n",
    "                    self.layers[self.OL].append(neuron_l(n_inputs,True))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    def copy(self):\n",
    "        new_network = SSNN_network()\n",
    "        new_network.outputs = self.outputs.copy()\n",
    "        new_network.HL = self.HL\n",
    "        new_network.OL = self.OL\n",
    "        new_network.HL = self.HL\n",
    "        for i in range(len(self.layers)):\n",
    "            new_network.layers.append([])            \n",
    "            for neuron in self.layers[i]:\n",
    "                new_network.layers[i].append(neuron.copy())\n",
    "        return new_network\n",
    "        \n",
    "    def forward_propagate(self, row):\n",
    "        for neuron in self.layers[0]:\n",
    "            for i in range(len(row)-1):\n",
    "                neuron.inputs[i] = row[i]\n",
    "\n",
    "        m_status = -1\n",
    "                \n",
    "        for l in range(len(self.layers)):\n",
    "            layer = self.layers[l]\n",
    "            for neuron in layer:\n",
    "                activation = neuron.activate()\n",
    "                neuron.transfer(activation)\n",
    "                if neuron.mode == 'C':\n",
    "                    if neuron.output > .5 and neuron.C == row[-1]:\n",
    "                        if neuron.R < m_status  or m_status == -1:\n",
    "                            m_status = neuron.R\n",
    "            if l < self.OL:\n",
    "                for neuron in self.layers[l+1]:\n",
    "                    for i in range(len(self.layers[l])):\n",
    "                        neuron2 = self.layers[l][i]\n",
    "                        neuron.inputs[i] = neuron2.output\n",
    "\n",
    "        outputs = []\n",
    "        for neuron in self.layers[self.OL]:\n",
    "            outputs.append(neuron.output)\n",
    "        return (outputs, m_status)\n",
    "     \n",
    "    \n",
    "    def backward_propagate_error(self, expected):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            errors = list()\n",
    "            if i != self.OL:\n",
    "                for j in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in self.layers[i + 1]:\n",
    "                        error += (neuron.activation_derivate_by_input(j) * neuron.delta)\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    #exp = expected[j] if neuron[\"C\"] == '0' else (1-expected[j])\n",
    "                    expt = expected[j] \n",
    "                    errors.append(expt - neuron.output)\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                neuron.delta = errors[j] * neuron.transfer_derivative()\n",
    "                #print(\"prop error\",neuron.delta, errors[j] , neuron.transfer_derivative())\n",
    "                \n",
    "    def test_update_weights(self, l_rate, train):\n",
    "        #print (\"Update weights test\")\n",
    "        acc = self.test_network(train)\n",
    "        err = self.get_error(train)\n",
    "        X = [0]\n",
    "        YE = [err]\n",
    "        YA = [acc]\n",
    "        #print (\"base:\",acc,err)\n",
    "        for l in [0.1 + 0.1*x for x in range(20)]:\n",
    "            networks = self.copy()\n",
    "            networks.update_weights(l)\n",
    "            acc = networks.test_network(train)\n",
    "            err = networks.get_error(train)\n",
    "            #print (l,\":\",acc,err)\n",
    "            X.append(l)\n",
    "            YE.append(err)\n",
    "            YA.append(acc)\n",
    "\n",
    "        plt.plot(X,YE)\n",
    "        plt.show()\n",
    "        plt.plot(X,YA)\n",
    "        plt.show()\n",
    "                \n",
    "            \n",
    "    def get_error(self, train):\n",
    "        train = self.normalize(train) \n",
    "        sum_error = 0\n",
    "        n_outputs = len(self.outputs)\n",
    "        for row in train:\n",
    "            voutputs = self.forward_propagate( row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            for i in range(n_outputs):\n",
    "                if self.outputs[i] == row[-1]:\n",
    "                    expected[i] = 1\n",
    "            sum_error += sum([(expected[i]-voutputs[i])**2 for i in range(len(expected))])\n",
    "        return sum_error\n",
    "\n",
    "    def test_network(self, train):\n",
    "        train = self.normalize(train)\n",
    "        n_outputs = len(self.outputs)\n",
    "        dbok = 0\n",
    "        for row in train:\n",
    "            voutputs = self.forward_propagate( row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            idx = voutputs.index(max(voutputs))\n",
    "            if self.outputs[idx] == row[-1]:\n",
    "                dbok += 1\n",
    "            #print (row, voutputs)\n",
    "        #print (\"accuray:\", dbok / len(train))\n",
    "        return dbok / len(train)\n",
    "    \n",
    "    def calculate_update(self, C, m_st):\n",
    "        for i in range(len(self.layers)):\n",
    "            for neuron in self.layers[i]:\n",
    "                neuron.calculate_update(C, m_st);\n",
    "    \n",
    "    def update_weights(self, l_rate):\n",
    "        for i in range(len(self.layers)):\n",
    "            for neuron in self.layers[i]:\n",
    "                neuron.update_weights(l_rate);\n",
    "\n",
    "    def train_network(self, train, l_rate, n_epoch, drf = 5):\n",
    "        train = self.normalize(train)\n",
    "        self.train_status = [-1 for _ in range(len(train))]\n",
    "        n_outputs = len(self.outputs)\n",
    "        self.draw_network( train)\n",
    "        self.print_network_param()\n",
    "        for epoch in range(n_epoch):\n",
    "            sum_error = 0\n",
    "            for row in train:\n",
    "                                          \n",
    "                (voutputs, cst)  = self.forward_propagate( row)\n",
    "                \n",
    "                expected = [0 for i in range(n_outputs)]\n",
    "                for i in range(n_outputs):\n",
    "                    if self.outputs[i] == row[-1]:\n",
    "                        expected[i] = 1\n",
    "                sum_error += sum([(expected[i]-voutputs[i])**2 for i in range(len(expected))])\n",
    "                \n",
    "                self.backward_propagate_error( expected)\n",
    "                \n",
    "                #if random() < 0.1:\n",
    "                #    self.test_update_weights(l_rate,train)\n",
    "\n",
    "                self.calculate_update(row[-1], cst)\n",
    "                \n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\n",
    "            #if epoch % drf == 0:\n",
    "            self.update_weights(l_rate)\n",
    "            self.draw_network( train)\n",
    "            self.print_network_param()\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            (voutputs, _) = self.forward_propagate( row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            for i in range(n_outputs):\n",
    "                if self.outputs[i] == row[-1]:\n",
    "                    expected[i] = 1\n",
    "            sum_error += sum([(expected[i]-voutputs[i])**2 for i in range(len(expected))])\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "              \n",
    "            \n",
    "    def draw_network (self, train):\n",
    "        figure, axes = plt.subplots()\n",
    "        axes.set_aspect( 1 )\n",
    "        for i in range(len(self.layers[self.OL])):\n",
    "            sn = self.layers[self.OL][i]\n",
    "            sn.draw_neuron(axes, plt)\n",
    "        for i in range(len(train)):\n",
    "            cl = 'blue' if train[i][2] > 0 else 'red'\n",
    "            cc = plt.Circle( (train[i][0], train[i][1] ), 0.03 ,fill = True, color =cl )   \n",
    "            axes.add_artist( cc)        \n",
    "\n",
    "        plt.xlim( -1 , 2) \n",
    "        plt.ylim( -1 , 2) \n",
    "        plt.title( 'Circle' ) \n",
    "        plt.show()            \n",
    "                \n",
    "    def print_network_param(self):\n",
    "        for layer in self.layers:\n",
    "            print (\"Layer ---------------\")\n",
    "            for neuron in layer:\n",
    "                neuron.print_neuron_param()\n",
    "            \n",
    "    def normalize (self, train):\n",
    "        mx = []\n",
    "        mn = []\n",
    "        for i in range(len(train[0])-1):\n",
    "            mx.append(max([x[i] for x in train ]))\n",
    "            mn.append(min([x[i] for x in train ]))\n",
    "        for row in train:\n",
    "            for i in range(len(row)-1):\n",
    "                row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "        return train\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1],\n",
    "    [0.673756466,5.508563011,1],\n",
    "    [1.373756466,6.108563011,1],\n",
    "    [1.93756466,7.108563011,1] \n",
    "    ]\n",
    "\n",
    "#seed(1966)\n",
    "\n",
    "n_inputs = len(T[0]) - 1\n",
    "network = SSNN_network()\n",
    "# CASE 1:  network.init(n_inputs, [],['S','S'],[0,1])\n",
    "network.init(n_inputs, [],['S','S','S'],[0,1,1])\n",
    "#network = set_network_1(network)\n",
    "#network.print_network_param()\n",
    "network.train_network( T, 0.1, 10,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
