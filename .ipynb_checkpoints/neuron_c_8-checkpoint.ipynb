{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "2 10 1000 3\n",
      "<BatchDataset shapes: ((None, 3), (None, 2)), types: (tf.float32, tf.float64)>\n",
      "input: tf.Tensor(\n",
      "[[0.8914187  0.44162735 0.2808851 ]\n",
      " [0.8515105  0.46186763 0.24088585]\n",
      " [0.67635417 0.07768797 0.1056074 ]\n",
      " [0.942432   0.7850282  0.04864224]\n",
      " [0.13471572 0.22203955 0.6862668 ]\n",
      " [0.6970358  0.06602696 0.04721393]\n",
      " [0.06776198 0.5567025  0.9401386 ]\n",
      " [0.92003983 0.8369356  0.01939357]\n",
      " [0.8942079  0.41677353 0.26042283]\n",
      " [0.95389813 0.7809099  0.05973615]\n",
      " [0.24062414 0.03391621 0.46969435]\n",
      " [0.65640914 0.05278561 0.47191405]\n",
      " [0.7091805  0.         0.13205338]\n",
      " [0.86896616 0.43564287 0.25718904]\n",
      " [0.22771984 0.06400549 0.4711761 ]\n",
      " [0.93484247 0.93178266 0.16285257]\n",
      " [0.7452247  0.08793405 0.0679831 ]\n",
      " [0.8668542  0.41336656 0.2919149 ]\n",
      " [0.8878456  0.7762019  0.05588934]\n",
      " [0.74989474 0.42231864 0.4683498 ]\n",
      " [0.69134665 0.15128346 0.4693992 ]\n",
      " [0.35709557 0.226434   0.7199237 ]\n",
      " [0.33078822 0.22774236 0.7373164 ]\n",
      " [0.85176957 0.3695334  0.27421528]\n",
      " [0.35536852 0.22738518 0.77066207]\n",
      " [0.36974928 0.16118768 0.7554601 ]\n",
      " [0.8609641  0.42534757 0.29798838]\n",
      " [0.702974   0.07427303 0.0951458 ]\n",
      " [0.19811799 0.09548564 0.4409985 ]\n",
      " [0.815021   0.511639   0.43352175]\n",
      " [0.7059724  0.07141637 0.4727142 ]\n",
      " [0.20110098 0.13432966 0.66891617]], shape=(32, 3), dtype=float32)\n",
      "labels tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(32, 2), dtype=float64)\n",
      "kernel  <tf.Variable 'nn__model_6/ss_layer_6/kernel:0' shape=(3, 12) dtype=float32, numpy=\n",
      "array([[ 0.64815485, -0.3559605 ,  0.20014353, -0.28112715,  0.09535905,\n",
      "        -0.35034025,  0.12817992, -0.5305331 ,  0.03162672, -0.08267911,\n",
      "        -0.02133827,  0.07015286],\n",
      "       [-0.03005282, -0.5115979 ,  0.08203132,  0.16849105,  0.4781897 ,\n",
      "         0.18680447, -0.02384542, -0.03511131,  0.14952978,  0.80725867,\n",
      "         0.11003426, -0.39055902],\n",
      "       [ 0.32035694, -0.15671906,  0.5563809 , -0.5291747 ,  0.15807222,\n",
      "        -0.5098055 ,  0.26924753,  0.06294397, -0.16664729, -0.16909388,\n",
      "         0.34415245,  0.04050118]], dtype=float32)>\n",
      "bias  <tf.Variable 'nn__model_6/ss_layer_6/bias:0' shape=(12,) dtype=float32, numpy=\n",
      "array([ 0.36303866, -0.6610081 ,  0.581913  , -0.4259494 ,  0.09560429,\n",
      "        0.4340688 ,  0.14831188, -0.382004  ,  0.09107548,  0.27110243,\n",
      "        0.92465997,  0.5509967 ], dtype=float32)>\n",
      "Tensor(\"datas:0\", shape=(32, 3), dtype=float32)\n",
      "Tensor(\"nn__model_6/ss_layer_6/ones:0\", shape=(32, 12), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-9-a2d2b17f19c0>:65 train_step  *\n        predictions = model(datas, training=True)\n    <ipython-input-9-a2d2b17f19c0>:57 call  *\n        x = self.d1(x)\n    <ipython-input-9-a2d2b17f19c0>:30 call  *\n        ddi = tf.multiply( tf.transpose(input), tf.ones([self.batchsize, self.num_outputs]) )\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:509 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6174 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 3 and 32 for '{{node nn__model_6/ss_layer_6/Mul}} = Mul[T=DT_FLOAT](nn__model_6/ss_layer_6/transpose, nn__model_6/ss_layer_6/ones_1)' with input shapes: [3,32], [32,12].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-86d9394d3063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"input:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mtest_datas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-9-a2d2b17f19c0>:65 train_step  *\n        predictions = model(datas, training=True)\n    <ipython-input-9-a2d2b17f19c0>:57 call  *\n        x = self.d1(x)\n    <ipython-input-9-a2d2b17f19c0>:30 call  *\n        ddi = tf.multiply( tf.transpose(input), tf.ones([self.batchsize, self.num_outputs]) )\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:509 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6174 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\kovacs\\anaconda3\\envs\\proba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 3 and 32 for '{{node nn__model_6/ss_layer_6/Mul}} = Mul[T=DT_FLOAT](nn__model_6/ss_layer_6/transpose, nn__model_6/ss_layer_6/ones_1)' with input shapes: [3,32], [32,12].\n"
     ]
    }
   ],
   "source": [
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,  num_outputs,activation=sigmoid):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = activation\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.batchsize = int(input_shape[0])\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=.3))\n",
    "        print (\"kernel \", self.kernel)\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=.5))\n",
    "        \n",
    "        print (\"bias \", self.bias)\n",
    "    \n",
    "\n",
    "    def call(self, input):\n",
    "        print (input)\n",
    "        print (tf.ones([self.batchsize, self.num_outputs]))\n",
    "        ddi = tf.multiply( tf.transpose(input), tf.ones([self.batchsize, self.num_outputs]) )\n",
    "        ddd = self.kernel-ddi\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =0)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        dd3 = tf.cast(dd3,tf.float32)\n",
    "        dd4 = tf.abs(self.bias)\n",
    "        result = tf.math.divide_no_nan(dd3,dd4)    \n",
    "        rr2 = tf.ones([self.batchsize, self.num_outputs]) -result\n",
    "        rr3 = tf.math.scalar_mul(6,rr2)\n",
    "        result = self.activation(rr3)\n",
    "        return result\n",
    "\n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "  def __init__(self,c,l,n,m):\n",
    "    self.C=c\n",
    "    self.L=l\n",
    "    self.N=n\n",
    "    self.M=m\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.d1 = SSLayer(4*self.M)\n",
    "    self.d2 = Dense(self.C)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(datas, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "C = 2\n",
    "L = 10\n",
    "N = 1000\n",
    "M = 3\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(C,L,N,M)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "print (\"--------------\")\n",
    "print (C, L, N, M)\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for datas, labels in train_ds:\n",
    "    print (\"input:\", datas)\n",
    "    print (\"labels\", labels)\n",
    "    train_step(datas, labels)\n",
    "\n",
    "  for test_datas, test_labels in test_ds:\n",
    "    test_step(test_datas, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kernel:0', 'bias:0']\n",
      "out:\n",
      "kernel <tf.Variable 'kernel:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[ 0.2523557 , -0.4805397 , -0.23506409,  0.3204259 ,  0.08248037],\n",
      "       [-0.04309471, -0.03324677, -0.0968312 , -0.27222425,  0.2576189 ],\n",
      "       [ 0.2890751 ,  0.2100241 , -0.10678596,  0.07982869, -0.51990956]],\n",
      "      dtype=float32)>\n",
      "bias <tf.Variable 'bias:0' shape=(5,) dtype=float32, numpy=\n",
      "array([-0.15722479,  0.3852226 ,  0.24986114,  0.3118788 ,  0.06286097],\n",
      "      dtype=float32)>\n",
      "ddi tf.Tensor(\n",
      "[[0.2 0.2 0.2 0.2 0.2]\n",
      " [0.3 0.3 0.3 0.3 0.3]\n",
      " [0.4 0.4 0.4 0.4 0.4]], shape=(3, 5), dtype=float32)\n",
      "ddd tf.Tensor(\n",
      "[[ 0.05235569 -0.6805397  -0.43506408  0.12042589 -0.11751963]\n",
      " [-0.3430947  -0.33324677 -0.3968312  -0.57222426 -0.04238111]\n",
      " [-0.1109249  -0.1899759  -0.506786   -0.32017133 -0.9199096 ]], shape=(3, 5), dtype=float32)\n",
      "dd0 tf.Tensor(\n",
      "[[0.00274112 0.46313432 0.18928075 0.0145024  0.01381086]\n",
      " [0.11771398 0.11105341 0.15747501 0.3274406  0.00179616]\n",
      " [0.01230433 0.03609084 0.25683203 0.10250968 0.84623367]], shape=(3, 5), dtype=float32)\n",
      "dd1 tf.Tensor([0.13275944 0.6102786  0.60358775 0.44445267 0.86184067], shape=(5,), dtype=float32)\n",
      "dd2 tf.Tensor([0.13275944 0.61027861 0.60358775 0.44445267 0.86184067], shape=(5,), dtype=float64)\n",
      "dd3 tf.Tensor([0.36436167 0.7812033  0.7769091  0.6666728  0.9283537 ], shape=(5,), dtype=float32)\n",
      "dd4 tf.Tensor([0.15722479 0.3852226  0.24986114 0.3118788  0.06286097], shape=(5,), dtype=float32)\n",
      "result tf.Tensor([ 2.317457   2.027927   3.1093636  2.1376023 14.768364 ], shape=(5,), dtype=float32)\n",
      "rr2 tf.Tensor([[ -1.317457   -1.0279269  -2.1093636  -1.1376023 -13.768364 ]], shape=(1, 5), dtype=float32)\n",
      "rr3 tf.Tensor([[ -7.904742   -6.1675615 -12.656181   -6.825614  -82.61018  ]], shape=(1, 5), dtype=float32)\n",
      "result tf.Tensor([[3.6883354e-04 2.0920038e-03 3.2484531e-06 1.0844171e-03 0.0000000e+00]], shape=(1, 5), dtype=float32)\n",
      "tf.Tensor([[3.6883354e-04 2.0920038e-03 3.2484531e-06 1.0844171e-03 0.0000000e+00]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# P 04\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_inputs, num_outputs,activation=sigmoid):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[num_inputs,\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=.3))\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=.5))\n",
    "        \n",
    "        self.activation = activation\n",
    "\n",
    "    def call(self, input):\n",
    "        print (\"kernel\", self.kernel)\n",
    "        print (\"bias\", self.bias)\n",
    "        ddi = tf.multiply( tf.transpose(input), tf.ones([1, self.num_outputs]) )\n",
    "        print (\"ddi\", ddi)\n",
    "        ddd = self.kernel-ddi\n",
    "        print (\"ddd\", ddd)\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        print (\"dd0\", dd0)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =0)\n",
    "        print (\"dd1\", dd1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        print (\"dd2\", dd2)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        dd3 = tf.cast(dd3,tf.float32)\n",
    "        print (\"dd3\", dd3)\n",
    "        dd4 = tf.abs(self.bias)\n",
    "        print (\"dd4\", dd4)\n",
    "        result = tf.math.divide_no_nan(dd3,dd4)    \n",
    "        print (\"result\", result)\n",
    "        rr2 = tf.ones([1, self.num_outputs]) -result\n",
    "        print (\"rr2\", rr2)\n",
    "        rr3 = tf.math.scalar_mul(6,rr2)\n",
    "        print (\"rr3\", rr3)\n",
    "        result = self.activation(rr3)\n",
    "        print (\"result\", result)\n",
    "        return result\n",
    "\n",
    "M_input = 3\n",
    "M_ouput = 5\n",
    "#layer = SSLayer(M_input, M_ouput)\n",
    "layer = SSLayer(M_input, M_ouput,activation=sigmoid)\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])\n",
    "\n",
    "a = np.array([[0.2, 0.3, 0.4]],dtype=\"float32\")\n",
    "print (\"out:\")\n",
    "print (layer(tf.constant(a)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "tf.Tensor([[ 10.911133    6.1613445 -17.000881   -8.46829   -11.545963 ]], shape=(1, 5), dtype=float32)\n",
      "['ss_layer_13/kernel:0', 'ss_layer_13/bias:0']\n",
      "<tf.Variable 'ss_layer_13/kernel:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[ 6.808793  , -2.8096771 , -0.8926972 ,  1.2995508 ,  4.6321363 ],\n",
      "       [ 2.1581118 , -3.11415   ,  0.6261549 , -0.4685134 ,  0.15324706],\n",
      "       [-0.28710544,  5.3778553 , -5.8494463 , -2.8967533 , -5.510189  ]],\n",
      "      dtype=float32)> <tf.Variable 'ss_layer_13/bias:0' shape=(5,) dtype=float32, numpy=\n",
      "array([ 0.15592939, -0.21368217, -0.21329248, -0.38312   , -0.35173374],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#P 03\n",
    "\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=4))\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs])\n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "M_input = 3\n",
    "M_ouput = 5\n",
    "layer = SSLayer(M_ouput)\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])\n",
    "\n",
    "a = np.array([[1.0, 2.3, 3.0]],dtype=\"float32\")\n",
    "print (layer(tf.constant(a)))\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])\n",
    "print (layer.kernel, layer.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((?, 3), (?, 3)), types: (tf.float32, tf.float64)>\n",
      "Epoch 1, Loss: 1.033753514289856, Accuracy: 49.77777862548828, Test Accuracy: 52.52525329589844\n",
      "Epoch 2, Loss: 1.009682059288025, Accuracy: 47.0, Test Accuracy: 47.47474670410156\n",
      "Epoch 3, Loss: 0.9931789040565491, Accuracy: 48.11111068725586, Test Accuracy: 46.46464538574219\n",
      "Epoch 4, Loss: 0.9799463152885437, Accuracy: 46.22222137451172, Test Accuracy: 47.47474670410156\n",
      "Epoch 5, Loss: 0.9679049253463745, Accuracy: 44.88888931274414, Test Accuracy: 54.54545593261719\n",
      "Epoch 6, Loss: 0.955437958240509, Accuracy: 49.11111068725586, Test Accuracy: 54.54545593261719\n",
      "Epoch 7, Loss: 0.9434725642204285, Accuracy: 49.5555534362793, Test Accuracy: 56.56565475463867\n",
      "Epoch 8, Loss: 0.9311975240707397, Accuracy: 49.5555534362793, Test Accuracy: 57.57575607299805\n",
      "Epoch 9, Loss: 0.921164870262146, Accuracy: 50.33333206176758, Test Accuracy: 59.5959587097168\n",
      "Epoch 10, Loss: 0.9115208387374878, Accuracy: 52.999996185302734, Test Accuracy: 61.61616516113281\n",
      "Epoch 11, Loss: 0.902012050151825, Accuracy: 56.222225189208984, Test Accuracy: 64.6464614868164\n",
      "Epoch 12, Loss: 0.8915043473243713, Accuracy: 59.5555534362793, Test Accuracy: 64.6464614868164\n",
      "Epoch 13, Loss: 0.8789395689964294, Accuracy: 60.44444274902344, Test Accuracy: 64.6464614868164\n",
      "Epoch 14, Loss: 0.8679172992706299, Accuracy: 62.33333206176758, Test Accuracy: 66.66667175292969\n",
      "Epoch 15, Loss: 0.8577970862388611, Accuracy: 66.55555725097656, Test Accuracy: 69.69696807861328\n",
      "Epoch 16, Loss: 0.8478503823280334, Accuracy: 68.66666412353516, Test Accuracy: 71.71717071533203\n",
      "Epoch 17, Loss: 0.8380421996116638, Accuracy: 69.55555725097656, Test Accuracy: 72.7272720336914\n",
      "Epoch 18, Loss: 0.8283132314682007, Accuracy: 69.66666412353516, Test Accuracy: 72.7272720336914\n",
      "Epoch 19, Loss: 0.8187068700790405, Accuracy: 69.77777099609375, Test Accuracy: 72.7272720336914\n",
      "Epoch 20, Loss: 0.8092485666275024, Accuracy: 69.77777099609375, Test Accuracy: 72.7272720336914\n"
     ]
    }
   ],
   "source": [
    "#P 02\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "  def __init__(self,c,l,n,m):\n",
    "    self.C=c\n",
    "    self.L=l\n",
    "    self.N=n\n",
    "    self.M=m\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.d1 = Dense(4*self.M, input_shape=(M,), activation='relu')\n",
    "    self.d2 = Dense(self.C)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(datas, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "    \n",
    "# Create an instance of the model\n",
    "model = NN_Model(3,10,1000,3)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for datas, labels in train_ds:\n",
    "    train_step(datas, labels)\n",
    "\n",
    "  for test_datas, test_labels in test_ds:\n",
    "    test_step(test_datas, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8914187  0.44162735 0.2808851 ]] [[0. 0. 1.]] [[-0.48727185 -0.22519372  0.577533  ]]\n",
      "Train on 900 samples\n",
      "Epoch 1/20\n",
      "900/900 [==============================] - 3s 3ms/sample - loss: 1.0977 - acc: 0.4044\n",
      "Epoch 2/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 1.0759 - acc: 0.4044\n",
      "Epoch 3/20\n",
      "900/900 [==============================] - 0s 23us/sample - loss: 1.0630 - acc: 0.4044\n",
      "Epoch 4/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 1.0532 - acc: 0.4044\n",
      "Epoch 5/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 1.0433 - acc: 0.4544\n",
      "Epoch 6/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 1.0337 - acc: 0.4800\n",
      "Epoch 7/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 1.0257 - acc: 0.5044\n",
      "Epoch 8/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 1.0186 - acc: 0.5044\n",
      "Epoch 9/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 1.0115 - acc: 0.5044\n",
      "Epoch 10/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 1.0042 - acc: 0.5044\n",
      "Epoch 11/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 0.9967 - acc: 0.5044\n",
      "Epoch 12/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9891 - acc: 0.5100\n",
      "Epoch 13/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 0.9809 - acc: 0.5389\n",
      "Epoch 14/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9725 - acc: 0.5444\n",
      "Epoch 15/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9641 - acc: 0.5711\n",
      "Epoch 16/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9557 - acc: 0.5944\n",
      "Epoch 17/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 0.9464 - acc: 0.6022\n",
      "Epoch 18/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 0.9370 - acc: 0.6044\n",
      "Epoch 19/20\n",
      "900/900 [==============================] - 0s 23us/sample - loss: 0.9288 - acc: 0.6100\n",
      "Epoch 20/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 0.9187 - acc: 0.6100\n",
      "99/1 - 3s - loss: 0.9506 - acc: 0.5758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9052198246271923, 0.57575756]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P 01\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "C=3\n",
    "L=10\n",
    "N=1000\n",
    "M=3\n",
    "#(x_train,y_train,x_test,y_test) = gen_data_array_s(C, L, N, M)\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(4*M, input_shape=(M,), activation='relu'),\n",
    "  tf.keras.layers.Dense(C)\n",
    "])\n",
    "\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "print(x_train[:1],y_train[:1], predictions)\n",
    "\n",
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]], shape=(6, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dd = [2,3,0,1,1,2]\n",
    "\n",
    "oo = tf.one_hot(dd, 4)\n",
    "print (oo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.04517666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "x = tf.constant(3.0)\n",
    "c1 = tf.constant(1.0)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    #y = tf.math.sin(x * x)\n",
    "    y = tf.math.divide(c1, c1 + tf.math.exp(-x))\n",
    "dy_dx = g.gradient(y, x) \n",
    "print(dy_dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2.82842712 1.41421356], shape=(2,), dtype=float64)\n",
      "tf.Tensor([1.41421356 0.70710678], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [1,4,1]])\n",
    "ta = tf.constant(a)\n",
    "b = np.array([[3, 2, 1],[1,3,2]])\n",
    "tb = tf.constant(b)\n",
    "tm = tf.math.multiply(ta-tb, ta-tb)\n",
    "dd = tf.math.reduce_sum(tm, axis =1)\n",
    "d2 = tf.cast(dd,tf.double)\n",
    "d3 = tf.sqrt(d2)\n",
    "dr = tf.fill([2], 2)\n",
    "dr2= tf.cast(dr,tf.double)\n",
    "print (dr)\n",
    "out = tf.math.divide_no_nan(d3,dr2)\n",
    "print (d3)\n",
    "print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.3 3.  5.2]\n",
      " [1.3 3.  5.2]\n",
      " [1.3 3.  5.2]\n",
      " [1.3 3.  5.2]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (tf.multiply( tf.ones([4,1]),tf.constant([1.3,3.0,5.2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2]], shape=(1, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2]\n",
      " [1]], shape=(2, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [1 2]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2]])\n",
    "y = tf.constant([[2], [1]])\n",
    "print (x)\n",
    "print (y)\n",
    "z = tf.matmul(y,x)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]], shape=(3, 2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3. 2.]\n",
      " [4. 3.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[7. 5.]\n",
      "  [7. 5.]]\n",
      "\n",
      " [[7. 5.]\n",
      "  [7. 5.]]\n",
      "\n",
      " [[7. 5.]\n",
      "  [7. 5.]]], shape=(3, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones([3,2,2])\n",
    "y = tf.constant([  [3., 2.], [4.,3.]])\n",
    "print (x)\n",
    "print (y)\n",
    "z = tf.matmul(x,y)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.8914187  0.44162735 0.2808851 ]]\n",
      "\n",
      " [[0.8515105  0.46186763 0.24088585]]\n",
      "\n",
      " [[0.67635417 0.07768797 0.1056074 ]]\n",
      "\n",
      " [[0.942432   0.7850282  0.04864224]]\n",
      "\n",
      " [[0.13471572 0.22203955 0.6862668 ]]\n",
      "\n",
      " [[0.6970358  0.06602696 0.04721393]]\n",
      "\n",
      " [[0.06776198 0.5567025  0.9401386 ]]\n",
      "\n",
      " [[0.92003983 0.8369356  0.01939357]]\n",
      "\n",
      " [[0.8942079  0.41677353 0.26042283]]\n",
      "\n",
      " [[0.95389813 0.7809099  0.05973615]]], shape=(10, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]\n",
      "\n",
      " [[ 0.64815485 -0.3559605   0.20014353 -0.28112715  0.09535905\n",
      "   -0.35034025  0.12817992 -0.5305331   0.03162672 -0.08267911\n",
      "   -0.02133827  0.07015286]\n",
      "  [-0.03005282 -0.5115979   0.08203132  0.16849105  0.4781897\n",
      "    0.18680447 -0.02384542 -0.03511131  0.14952978  0.80725867\n",
      "    0.11003426 -0.39055902]\n",
      "  [ 0.32035694 -0.15671906  0.5563809  -0.5291747   0.15807222\n",
      "   -0.5098055   0.26924753  0.06294397 -0.16664729 -0.16909388\n",
      "    0.34415245  0.04050118]]], shape=(10, 3, 12), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.6544887  -0.5872655   0.3709181  -0.32482904  0.34058663\n",
      "   -0.37299865  0.17935881 -0.4707532   0.04742035  0.23530985\n",
      "    0.1262401  -0.0985698 ]]\n",
      "\n",
      " [[ 0.61519974 -0.577146    0.34233624 -0.28903288  0.34013695\n",
      "   -0.3348444   0.16299105 -0.45280898  0.05585049  0.2617122\n",
      "    0.11555296 -0.11089452]]\n",
      "\n",
      " [[ 0.46987957 -0.29705104  0.20049872 -0.23293656  0.11833967\n",
      "   -0.27628085  0.11327705 -0.35490862  0.01540835 -0.01106364\n",
      "    0.03046116  0.02138366]]\n",
      "\n",
      " [[ 0.60283244 -0.74471056  0.28008217 -0.15841322  0.47295082\n",
      "   -0.20832315  0.11517834 -0.524493    0.13908504  0.5475763\n",
      "    0.08301047 -0.23851548]]\n",
      "\n",
      " [[ 0.30049405 -0.26909953  0.42700243 -0.36361557  0.2275031\n",
      "   -0.35558093  0.19674885 -0.03607089 -0.07690235  0.05206168\n",
      "    0.25773776 -0.04947424]]\n",
      "\n",
      " [[ 0.46492815 -0.28929576  0.17119241 -0.20981516  0.1055053\n",
      "   -0.2559355   0.10048378 -0.369147    0.02404988 -0.01231304\n",
      "    0.00864048  0.02502384]]\n",
      "\n",
      " [[ 0.32836968 -0.45626605  0.5823043  -0.42274788  0.4212809\n",
      "   -0.39903307  0.24854091  0.00367953 -0.07128485  0.28482872\n",
      "    0.38336143 -0.17459476]]\n",
      "\n",
      " [[ 0.5773889  -0.7587117   0.26358515 -0.12789463  0.4910137\n",
      "   -0.17587063  0.10319523 -0.5162768   0.15101275  0.59627604\n",
      "    0.07913387 -0.26154384]]\n",
      "\n",
      " [[ 0.65048826 -0.5723363   0.35805267 -0.3189727   0.32573324\n",
      "   -0.36818683  0.17479956 -0.4726483   0.04720217  0.21847582\n",
      "    0.11640367 -0.08949599]]\n",
      "\n",
      " [[ 0.613942   -0.7484237   0.28821167 -0.1682012   0.47382852\n",
      "   -0.21876526  0.11973327 -0.52973324  0.1369831   0.54142785\n",
      "    0.08613065 -0.23565334]]], shape=(10, 1, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "In = tf.constant([[0.8914187,  0.44162735, 0.2808851 ],\n",
    " [0.8515105,  0.46186763, 0.24088585],\n",
    " [0.67635417, 0.07768797, 0.1056074 ],\n",
    " [0.942432,   0.7850282,  0.04864224],\n",
    " [0.13471572, 0.22203955, 0.6862668 ],\n",
    " [0.6970358,  0.06602696, 0.04721393],\n",
    " [0.06776198, 0.5567025,  0.9401386 ],\n",
    " [0.92003983, 0.8369356,  0.01939357],\n",
    " [0.8942079,  0.41677353, 0.26042283],\n",
    " [0.95389813, 0.7809099,  0.05973615]])\n",
    "InD = tf.reshape(In,[10,1,3]) \n",
    "print (InD)\n",
    "W = tf.constant([[ 0.64815485, -0.3559605 ,  0.20014353, -0.28112715,  0.09535905,\n",
    "        -0.35034025,  0.12817992, -0.5305331 ,  0.03162672, -0.08267911,\n",
    "        -0.02133827,  0.07015286],\n",
    "       [-0.03005282, -0.5115979 ,  0.08203132,  0.16849105,  0.4781897 ,\n",
    "         0.18680447, -0.02384542, -0.03511131,  0.14952978,  0.80725867,\n",
    "         0.11003426, -0.39055902],\n",
    "       [ 0.32035694, -0.15671906,  0.5563809 , -0.5291747 ,  0.15807222,\n",
    "        -0.5098055 ,  0.26924753,  0.06294397, -0.16664729, -0.16909388,\n",
    "         0.34415245,  0.04050118]])\n",
    "WD = tf.stack([W] * 10)\n",
    "print (WD)\n",
    "R = tf.matmul(InD, WD)\n",
    "print (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [1 4 1]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [1 4 1]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [1 4 1]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [1 4 1]]], shape=(4, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "vec = tf.constant([[1,2,3],[4,5,6]])  # shape=(2,3)\n",
    "matrix = tf.stack([a] * 4)  # shape=(4,2,3)\n",
    "\n",
    "\n",
    "print(vec)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
