{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((?, 3), (?, 3)), types: (tf.float32, tf.float64)>\n",
      "kernel  <tf.Variable 'nn__model_5/ss_layer_15/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
      "array([[ 0.14033231,  0.28285164,  0.20580843],\n",
      "       [ 0.39156663,  0.08243324,  0.83312654],\n",
      "       [-0.0426203 ,  0.52840155, -0.11824543]], dtype=float32)>\n",
      "bias  <tf.Variable 'nn__model_5/ss_layer_15/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.21135099,  0.15881996, -0.3506447 ], dtype=float32)>\n",
      "Tensor(\"datas:0\", shape=(32, 3), dtype=float32)\n",
      "Tensor(\"nn__model_5/ss_layer_15/ones:0\", shape=(32, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-24-ea3a927ef03d>:65 train_step  *\n        predictions = model(datas, training=True)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-24-ea3a927ef03d>:57 call  *\n        x = self.d1(x)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-24-ea3a927ef03d>:30 call  *\n        ddi = tf.multiply( tf.transpose(input), tf.ones([self.batchsize, self.num_outputs]) )\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:331 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:6700 mul\n        \"Mul\", x=x, y=y, name=name)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\n        compute_device)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3426 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1770 __init__\n        control_input_ops)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 3 and 32 for 'nn__model_5/ss_layer_15/Mul' (op: 'Mul') with input shapes: [3,32], [32,3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ea3a927ef03d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mtest_datas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    390\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    391\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 392\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2147\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2148\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2036\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2037\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2038\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2039\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-24-ea3a927ef03d>:65 train_step  *\n        predictions = model(datas, training=True)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-24-ea3a927ef03d>:57 call  *\n        x = self.d1(x)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:854 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    <ipython-input-24-ea3a927ef03d>:30 call  *\n        ddi = tf.multiply( tf.transpose(input), tf.ones([self.batchsize, self.num_outputs]) )\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:331 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:6700 mul\n        \"Mul\", x=x, y=y, name=name)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:794 _apply_op_helper\n        op_def=op_def)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\n        compute_device)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3426 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1770 __init__\n        control_input_ops)\n    C:\\Users\\KL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1610 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 3 and 32 for 'nn__model_5/ss_layer_15/Mul' (op: 'Mul') with input shapes: [3,32], [32,3].\n"
     ]
    }
   ],
   "source": [
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,  num_outputs,activation=sigmoid):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = activation\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.batchsize = int(input_shape[0])\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=.3))\n",
    "        print (\"kernel \", self.kernel)\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=.5))\n",
    "        \n",
    "        print (\"bias \", self.bias)\n",
    "    \n",
    "\n",
    "    def call(self, input):\n",
    "        print (input)\n",
    "        print (tf.ones([self.batchsize, self.num_outputs]))\n",
    "        ddi = tf.multiply( tf.transpose(input), tf.ones([self.batchsize, self.num_outputs]) )\n",
    "        ddd = self.kernel-ddi\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =0)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        dd3 = tf.cast(dd3,tf.float32)\n",
    "        dd4 = tf.abs(self.bias)\n",
    "        result = tf.math.divide_no_nan(dd3,dd4)    \n",
    "        rr2 = tf.ones([self.batchsize, self.num_outputs]) -result\n",
    "        rr3 = tf.math.scalar_mul(6,rr2)\n",
    "        result = self.activation(rr3)\n",
    "        return result\n",
    "\n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "  def __init__(self,c,l,n,m):\n",
    "    self.C=c\n",
    "    self.L=l\n",
    "    self.N=n\n",
    "    self.M=m\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.d1 = SSLayer(self.M, 4*self.M)\n",
    "    self.d2 = Dense(self.C)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(datas, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "C = 3\n",
    "L = 10\n",
    "N = 1000\n",
    "M = 3\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(3,10,1000,3)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for datas, labels in train_ds:\n",
    "    train_step(datas, labels)\n",
    "\n",
    "  for test_datas, test_labels in test_ds:\n",
    "    test_step(test_datas, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kernel:0', 'bias:0']\n",
      "out:\n",
      "kernel <tf.Variable 'kernel:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[ 0.2523557 , -0.4805397 , -0.23506409,  0.3204259 ,  0.08248037],\n",
      "       [-0.04309471, -0.03324677, -0.0968312 , -0.27222425,  0.2576189 ],\n",
      "       [ 0.2890751 ,  0.2100241 , -0.10678596,  0.07982869, -0.51990956]],\n",
      "      dtype=float32)>\n",
      "bias <tf.Variable 'bias:0' shape=(5,) dtype=float32, numpy=\n",
      "array([-0.15722479,  0.3852226 ,  0.24986114,  0.3118788 ,  0.06286097],\n",
      "      dtype=float32)>\n",
      "ddi tf.Tensor(\n",
      "[[0.2 0.2 0.2 0.2 0.2]\n",
      " [0.3 0.3 0.3 0.3 0.3]\n",
      " [0.4 0.4 0.4 0.4 0.4]], shape=(3, 5), dtype=float32)\n",
      "ddd tf.Tensor(\n",
      "[[ 0.05235569 -0.6805397  -0.43506408  0.12042589 -0.11751963]\n",
      " [-0.3430947  -0.33324677 -0.3968312  -0.57222426 -0.04238111]\n",
      " [-0.1109249  -0.1899759  -0.506786   -0.32017133 -0.9199096 ]], shape=(3, 5), dtype=float32)\n",
      "dd0 tf.Tensor(\n",
      "[[0.00274112 0.46313432 0.18928075 0.0145024  0.01381086]\n",
      " [0.11771398 0.11105341 0.15747501 0.3274406  0.00179616]\n",
      " [0.01230433 0.03609084 0.25683203 0.10250968 0.84623367]], shape=(3, 5), dtype=float32)\n",
      "dd1 tf.Tensor([0.13275944 0.6102786  0.60358775 0.44445267 0.86184067], shape=(5,), dtype=float32)\n",
      "dd2 tf.Tensor([0.13275944 0.61027861 0.60358775 0.44445267 0.86184067], shape=(5,), dtype=float64)\n",
      "dd3 tf.Tensor([0.36436167 0.7812033  0.7769091  0.6666728  0.9283537 ], shape=(5,), dtype=float32)\n",
      "dd4 tf.Tensor([0.15722479 0.3852226  0.24986114 0.3118788  0.06286097], shape=(5,), dtype=float32)\n",
      "result tf.Tensor([ 2.317457   2.027927   3.1093636  2.1376023 14.768364 ], shape=(5,), dtype=float32)\n",
      "rr2 tf.Tensor([[ -1.317457   -1.0279269  -2.1093636  -1.1376023 -13.768364 ]], shape=(1, 5), dtype=float32)\n",
      "rr3 tf.Tensor([[ -7.904742   -6.1675615 -12.656181   -6.825614  -82.61018  ]], shape=(1, 5), dtype=float32)\n",
      "result tf.Tensor([[3.6883354e-04 2.0920038e-03 3.2484531e-06 1.0844171e-03 0.0000000e+00]], shape=(1, 5), dtype=float32)\n",
      "tf.Tensor([[3.6883354e-04 2.0920038e-03 3.2484531e-06 1.0844171e-03 0.0000000e+00]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# P 04\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_inputs, num_outputs,activation=sigmoid):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[num_inputs,\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=.3))\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=.5))\n",
    "        \n",
    "        self.activation = activation\n",
    "\n",
    "    def call(self, input):\n",
    "        print (\"kernel\", self.kernel)\n",
    "        print (\"bias\", self.bias)\n",
    "        ddi = tf.multiply( tf.transpose(input), tf.ones([1, self.num_outputs]) )\n",
    "        print (\"ddi\", ddi)\n",
    "        ddd = self.kernel-ddi\n",
    "        print (\"ddd\", ddd)\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        print (\"dd0\", dd0)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =0)\n",
    "        print (\"dd1\", dd1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        print (\"dd2\", dd2)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        dd3 = tf.cast(dd3,tf.float32)\n",
    "        print (\"dd3\", dd3)\n",
    "        dd4 = tf.abs(self.bias)\n",
    "        print (\"dd4\", dd4)\n",
    "        result = tf.math.divide_no_nan(dd3,dd4)    \n",
    "        print (\"result\", result)\n",
    "        rr2 = tf.ones([1, self.num_outputs]) -result\n",
    "        print (\"rr2\", rr2)\n",
    "        rr3 = tf.math.scalar_mul(6,rr2)\n",
    "        print (\"rr3\", rr3)\n",
    "        result = self.activation(rr3)\n",
    "        print (\"result\", result)\n",
    "        return result\n",
    "\n",
    "M_input = 3\n",
    "M_ouput = 5\n",
    "#layer = SSLayer(M_input, M_ouput)\n",
    "layer = SSLayer(M_input, M_ouput,activation=sigmoid)\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])\n",
    "\n",
    "a = np.array([[0.2, 0.3, 0.4]],dtype=\"float32\")\n",
    "print (\"out:\")\n",
    "print (layer(tf.constant(a)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "tf.Tensor([[ 10.911133    6.1613445 -17.000881   -8.46829   -11.545963 ]], shape=(1, 5), dtype=float32)\n",
      "['ss_layer_13/kernel:0', 'ss_layer_13/bias:0']\n",
      "<tf.Variable 'ss_layer_13/kernel:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[ 6.808793  , -2.8096771 , -0.8926972 ,  1.2995508 ,  4.6321363 ],\n",
      "       [ 2.1581118 , -3.11415   ,  0.6261549 , -0.4685134 ,  0.15324706],\n",
      "       [-0.28710544,  5.3778553 , -5.8494463 , -2.8967533 , -5.510189  ]],\n",
      "      dtype=float32)> <tf.Variable 'ss_layer_13/bias:0' shape=(5,) dtype=float32, numpy=\n",
      "array([ 0.15592939, -0.21368217, -0.21329248, -0.38312   , -0.35173374],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#P 03\n",
    "\n",
    "\n",
    "class SSLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(SSLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs], \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=4))\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs])\n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "M_input = 3\n",
    "M_ouput = 5\n",
    "layer = SSLayer(M_ouput)\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])\n",
    "\n",
    "a = np.array([[1.0, 2.3, 3.0]],dtype=\"float32\")\n",
    "print (layer(tf.constant(a)))\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])\n",
    "print (layer.kernel, layer.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((?, 3), (?, 3)), types: (tf.float32, tf.float64)>\n",
      "Epoch 1, Loss: 1.033753514289856, Accuracy: 49.77777862548828, Test Accuracy: 52.52525329589844\n",
      "Epoch 2, Loss: 1.009682059288025, Accuracy: 47.0, Test Accuracy: 47.47474670410156\n",
      "Epoch 3, Loss: 0.9931789040565491, Accuracy: 48.11111068725586, Test Accuracy: 46.46464538574219\n",
      "Epoch 4, Loss: 0.9799463152885437, Accuracy: 46.22222137451172, Test Accuracy: 47.47474670410156\n",
      "Epoch 5, Loss: 0.9679049253463745, Accuracy: 44.88888931274414, Test Accuracy: 54.54545593261719\n",
      "Epoch 6, Loss: 0.955437958240509, Accuracy: 49.11111068725586, Test Accuracy: 54.54545593261719\n",
      "Epoch 7, Loss: 0.9434725642204285, Accuracy: 49.5555534362793, Test Accuracy: 56.56565475463867\n",
      "Epoch 8, Loss: 0.9311975240707397, Accuracy: 49.5555534362793, Test Accuracy: 57.57575607299805\n",
      "Epoch 9, Loss: 0.921164870262146, Accuracy: 50.33333206176758, Test Accuracy: 59.5959587097168\n",
      "Epoch 10, Loss: 0.9115208387374878, Accuracy: 52.999996185302734, Test Accuracy: 61.61616516113281\n",
      "Epoch 11, Loss: 0.902012050151825, Accuracy: 56.222225189208984, Test Accuracy: 64.6464614868164\n",
      "Epoch 12, Loss: 0.8915043473243713, Accuracy: 59.5555534362793, Test Accuracy: 64.6464614868164\n",
      "Epoch 13, Loss: 0.8789395689964294, Accuracy: 60.44444274902344, Test Accuracy: 64.6464614868164\n",
      "Epoch 14, Loss: 0.8679172992706299, Accuracy: 62.33333206176758, Test Accuracy: 66.66667175292969\n",
      "Epoch 15, Loss: 0.8577970862388611, Accuracy: 66.55555725097656, Test Accuracy: 69.69696807861328\n",
      "Epoch 16, Loss: 0.8478503823280334, Accuracy: 68.66666412353516, Test Accuracy: 71.71717071533203\n",
      "Epoch 17, Loss: 0.8380421996116638, Accuracy: 69.55555725097656, Test Accuracy: 72.7272720336914\n",
      "Epoch 18, Loss: 0.8283132314682007, Accuracy: 69.66666412353516, Test Accuracy: 72.7272720336914\n",
      "Epoch 19, Loss: 0.8187068700790405, Accuracy: 69.77777099609375, Test Accuracy: 72.7272720336914\n",
      "Epoch 20, Loss: 0.8092485666275024, Accuracy: 69.77777099609375, Test Accuracy: 72.7272720336914\n"
     ]
    }
   ],
   "source": [
    "#P 02\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "  def __init__(self,c,l,n,m):\n",
    "    self.C=c\n",
    "    self.L=l\n",
    "    self.N=n\n",
    "    self.M=m\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.d1 = Dense(4*self.M, input_shape=(M,), activation='relu')\n",
    "    self.d2 = Dense(self.C)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(datas, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "\n",
    "    \n",
    "# Create an instance of the model\n",
    "model = NN_Model(3,10,1000,3)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for datas, labels in train_ds:\n",
    "    train_step(datas, labels)\n",
    "\n",
    "  for test_datas, test_labels in test_ds:\n",
    "    test_step(test_datas, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8914187  0.44162735 0.2808851 ]] [[0. 0. 1.]] [[-0.48727185 -0.22519372  0.577533  ]]\n",
      "Train on 900 samples\n",
      "Epoch 1/20\n",
      "900/900 [==============================] - 3s 3ms/sample - loss: 1.0977 - acc: 0.4044\n",
      "Epoch 2/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 1.0759 - acc: 0.4044\n",
      "Epoch 3/20\n",
      "900/900 [==============================] - 0s 23us/sample - loss: 1.0630 - acc: 0.4044\n",
      "Epoch 4/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 1.0532 - acc: 0.4044\n",
      "Epoch 5/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 1.0433 - acc: 0.4544\n",
      "Epoch 6/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 1.0337 - acc: 0.4800\n",
      "Epoch 7/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 1.0257 - acc: 0.5044\n",
      "Epoch 8/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 1.0186 - acc: 0.5044\n",
      "Epoch 9/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 1.0115 - acc: 0.5044\n",
      "Epoch 10/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 1.0042 - acc: 0.5044\n",
      "Epoch 11/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 0.9967 - acc: 0.5044\n",
      "Epoch 12/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9891 - acc: 0.5100\n",
      "Epoch 13/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 0.9809 - acc: 0.5389\n",
      "Epoch 14/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9725 - acc: 0.5444\n",
      "Epoch 15/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9641 - acc: 0.5711\n",
      "Epoch 16/20\n",
      "900/900 [==============================] - 0s 24us/sample - loss: 0.9557 - acc: 0.5944\n",
      "Epoch 17/20\n",
      "900/900 [==============================] - 0s 26us/sample - loss: 0.9464 - acc: 0.6022\n",
      "Epoch 18/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 0.9370 - acc: 0.6044\n",
      "Epoch 19/20\n",
      "900/900 [==============================] - 0s 23us/sample - loss: 0.9288 - acc: 0.6100\n",
      "Epoch 20/20\n",
      "900/900 [==============================] - 0s 25us/sample - loss: 0.9187 - acc: 0.6100\n",
      "99/1 - 3s - loss: 0.9506 - acc: 0.5758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9052198246271923, 0.57575756]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P 01\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "C=3\n",
    "L=10\n",
    "N=1000\n",
    "M=3\n",
    "#(x_train,y_train,x_test,y_test) = gen_data_array_s(C, L, N, M)\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(4*M, input_shape=(M,), activation='relu'),\n",
    "  tf.keras.layers.Dense(C)\n",
    "])\n",
    "\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "print(x_train[:1],y_train[:1], predictions)\n",
    "\n",
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]], shape=(6, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dd = [2,3,0,1,1,2]\n",
    "\n",
    "oo = tf.one_hot(dd, 4)\n",
    "print (oo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.04517666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "x = tf.constant(3.0)\n",
    "c1 = tf.constant(1.0)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    #y = tf.math.sin(x * x)\n",
    "    y = tf.math.divide(c1, c1 + tf.math.exp(-x))\n",
    "dy_dx = g.gradient(y, x) \n",
    "print(dy_dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2.82842712 1.41421356], shape=(2,), dtype=float64)\n",
      "tf.Tensor([1.41421356 0.70710678], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [1,4,1]])\n",
    "ta = tf.constant(a)\n",
    "b = np.array([[3, 2, 1],[1,3,2]])\n",
    "tb = tf.constant(b)\n",
    "tm = tf.math.multiply(ta-tb, ta-tb)\n",
    "dd = tf.math.reduce_sum(tm, axis =1)\n",
    "d2 = tf.cast(dd,tf.double)\n",
    "d3 = tf.sqrt(d2)\n",
    "dr = tf.fill([2], 2)\n",
    "dr2= tf.cast(dr,tf.double)\n",
    "print (dr)\n",
    "out = tf.math.divide_no_nan(d3,dr2)\n",
    "print (d3)\n",
    "print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.3 3.  5.2]\n",
      " [1.3 3.  5.2]\n",
      " [1.3 3.  5.2]\n",
      " [1.3 3.  5.2]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (tf.multiply( tf.ones([4,1]),tf.constant([1.3,3.0,5.2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2]], shape=(1, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2]\n",
      " [1]], shape=(2, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [1 2]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2]])\n",
    "y = tf.constant([[2], [1]])\n",
    "print (x)\n",
    "print (y)\n",
    "z = tf.matmul(y,x)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]], shape=(3, 2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3. 2.]\n",
      " [4. 3.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[7. 5.]\n",
      "  [7. 5.]]\n",
      "\n",
      " [[7. 5.]\n",
      "  [7. 5.]]\n",
      "\n",
      " [[7. 5.]\n",
      "  [7. 5.]]], shape=(3, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones([3,2,2])\n",
    "y = tf.constant([  [3., 2.], [4.,3.]])\n",
    "print (x)\n",
    "print (y)\n",
    "z = tf.matmul(x,y)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
