{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sphere-Plane NN model\n",
    "## https://www.adeveloperdiary.com/data-science/machine-learning/understand-and-implement-the-backpropagation-algorithm-from-scratch-in-python/\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from math import exp\n",
    "from math import sqrt\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import sample\n",
    "import matplotlib.lines as lines \n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    " \n",
    "# Initialize a network\n",
    "\n",
    "\n",
    "class neuron_s():\n",
    "    \n",
    "    def __init__(self, n_inputs,c,o):\n",
    "        self.mode = \"C\"\n",
    "        self.outlayer = o\n",
    "        self.inputs = [0 for _ in range(n_inputs)]\n",
    "        self.weights = [random() for _ in range(n_inputs)]\n",
    "\n",
    "        self.delta = 0\n",
    "        self.output = 0\n",
    "        self.R = .05 + 0.15*random()\n",
    "        self.C = c\n",
    "        self.al = 0.1\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dR = 0\n",
    "\n",
    "        # adam parameters\n",
    "        self.m_dw = [0 for _ in range(n_inputs)] \n",
    "        self.v_dw = [0 for _ in range(n_inputs)] \n",
    "        self.m_dR = 0 \n",
    "        self.v_dR = 0\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.eta = 0.01        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def copy (self):\n",
    "        new_neuron = neuron_s(len(self.inputs), self.C, self.outlayer)\n",
    "        new_neuron.inputs = self.inputs.copy()\n",
    "        new_neuron.weights = self.weights.copy()\n",
    "        new_neuron.delta = self.delta\n",
    "        new_neuron.output = self.output\n",
    "        new_neuron.R = self.R\n",
    "        new_neuron.dR = self.dR\n",
    "        new_neuron.dw = self.dw.copy()\n",
    "        return new_neuron\n",
    "    \n",
    "    def activate(self):\n",
    "        N = len(self.weights)\n",
    "        y1 = sum([self.inputs[i]* self.inputs[i] for i in range(N) ])\n",
    "        y2 = sum([self.inputs[i]* self.weights[i] for i in range(N) ])\n",
    "        y3 = sum([self.weights[i]* self.weights[i] for i in range(N) ])\n",
    " \n",
    "        activation = 1 - (y3 -  2*y2 + y1 )/(self.R**2)\n",
    "        return activation\n",
    "        \n",
    "    def transfer_l(self,activation):\n",
    "        self.output = activation\n",
    "        return self.output\n",
    "    \n",
    "    def transfer_derivative_l(self):\n",
    "        return 1\n",
    "    \n",
    "    def transfer(self,activation):\n",
    "        \n",
    "        if  -self.al*activation > 100:\n",
    "            self.output = 0\n",
    "        else:\n",
    "            self.output = 1.0 / (1.0 + exp(-self.al*activation)) \n",
    "        return self.output\n",
    "    \n",
    "    def transfer_derivative(self):\n",
    "        return self.al*self.output * (1.0 - self.output)\n",
    "\n",
    "    # Calculate the derivative of the activation function\n",
    "    def activation_derivate_by_input(self, idx):\n",
    "        return 2*(self.weights[idx]-self.inputs[idx])/(self.R**2)\n",
    "\n",
    "    def activation_derivate_by_weight(self, idx):\n",
    "        return 2*(-self.weights[idx]+self.inputs[idx])/(self.R**2)\n",
    "\n",
    "    def activation_derivate_by_R(self):\n",
    "        N = len(self.weights)\n",
    "        y1 = sum([self.inputs[i]* self.inputs[i] for i in range(N) ])\n",
    "        y2 = sum([self.inputs[i]* self.weights[i] for i in range(N) ])\n",
    "        y3 = sum([self.weights[i]* self.weights[i] for i in range(N) ])\n",
    "        return 2*(y3 - 2*y2 +y1)  / (self.R**3) \n",
    "    \n",
    "    def print_neuron_param(self):\n",
    "        print(self.weights, self.R,self.C)\n",
    "        \n",
    "    def calculate_update(self, Ct, m_st):\n",
    "        if self.output < .5 and self.C != Ct:\n",
    "            return\n",
    "        \n",
    "        if self.output < .5 and m_st:\n",
    "            return\n",
    "        \n",
    "        for j in range(len(self.weights)):\n",
    "            self.dw[j] += ( self.delta * self.activation_derivate_by_weight(j))\n",
    "        self.dR += self.delta*self.activation_derivate_by_R()\n",
    "        #print(self.C,self.delta, self.activation_derivate_by_R(), self.delta*self.activation_derivate_by_R())\n",
    "        \n",
    "    def update_weights_adam(self, l_rate, t):\n",
    "        for j in range(len(self.weights)):\n",
    "            self.m_dw[j] = self.beta1*self.m_dw[j] + (1-self.beta1)*self.dw[j]\n",
    "        # *** biases *** #\n",
    "        self.m_dR = self.beta1*self.m_dR + (1-self.beta1)*self.dR\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        for j in range(len(self.weights)):\n",
    "            self.v_dw[j] = self.beta2*self.v_dw[j] + (1-self.beta2)*(self.dw[j]**2)\n",
    "        # *** biases *** #\n",
    "        self.v_dR = self.beta2*self.v_dR + (1-self.beta2)*(self.dR**2)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = [0 for _ in range(len(self.weights))] \n",
    "        v_dw_corr = [0 for _ in range(len(self.weights))] \n",
    "        for j in range(len(self.weights)):\n",
    "            m_dw_corr[j] = self.m_dw[j]/(1-self.beta1**t)\n",
    "        m_dR_corr = self.m_dR/(1-self.beta1**t)\n",
    "        for j in range(len(self.weights)):\n",
    "            v_dw_corr[j] = self.v_dw[j]/(1-self.beta2**t)\n",
    "        v_dR_corr = self.v_dR/(1-self.beta2**t)\n",
    "        \n",
    "        for j in range(len(self.weights)):\n",
    "            self.weights[j] -= self.eta*(m_dw_corr[j]/(np.sqrt(v_dw_corr[j])+self.epsilon))\n",
    "        self.R -= self.eta*(m_dR_corr/(np.sqrt(v_dR_corr)+self.epsilon))\n",
    "        \n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dR = 0\n",
    "        \n",
    "\n",
    "    def update_weights(self, l_rate):\n",
    "        #print (\"update weights\")\n",
    "        \n",
    "        dH = sqrt(sum([x**2 for x in self.dw]) + self.dR**2 )*.5\n",
    "        if dH < 0.000001:\n",
    "            dH = 1\n",
    "\n",
    "        #print (\"update :\", self.inputs)\n",
    "        for j in range(len(self.weights)):\n",
    "            #print (\"   \", self.weights[j],self.dw[j]/dH ,\" == > \" ,self.weights[j] + l_rate * self.dw[j]/dH)\n",
    "            self.weights[j] -= l_rate * self.dw[j]/dH\n",
    "            \n",
    "        #print (\"   \", self.R,self.dR/dH,\" == > \" ,self.R + l_rate * self.dR/dH)\n",
    "        self.R -= l_rate * self.dR/dH\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dR = 0\n",
    "                \n",
    "        \n",
    "class neuron_l():\n",
    "    \n",
    "    def __init__(self, n_inputs,c, o):\n",
    "        self.mode = \"L\"\n",
    "        self.C = c\n",
    "        self.outlayer = o\n",
    "        self.inputs = [0 for _ in range(n_inputs)]\n",
    "        self.weights = [random() -.5 for _ in range(n_inputs)]\n",
    "        self.delta = 0\n",
    "        self.output = 0\n",
    "        self.A = random() - .5\n",
    "        #s1 = sqrt(sum([x**2 for x in self.weights]))\n",
    "        #self.weights = [x / s1 for x in self.weights]\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dA = 0\n",
    "        \n",
    "        # adam parameters\n",
    "        self.m_dw = [0 for _ in range(n_inputs)] \n",
    "        self.v_dw = [0 for _ in range(n_inputs)] \n",
    "        self.m_dA = 0 \n",
    "        self.v_dA = 0\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.eta = 0.01        \n",
    "        \n",
    "        \n",
    "    def copy (self):\n",
    "        new_neuron = neuron_l(len(self.inputs),  self.C, self.outlayer)\n",
    "        new_neuron.inputs = self.inputs.copy()\n",
    "        new_neuron.weights = self.weights.copy()\n",
    "        new_neuron.delta = self.delta\n",
    "        new_neuron.output = self.output\n",
    "        new_neuron.A = self.A\n",
    "        new_neuron.dA = self.dA\n",
    "        new_neuron.dw = self.dw.copy()\n",
    "        return new_neuron\n",
    "\n",
    "    def activate(self):\n",
    "        N = len(self.weights)\n",
    "        y1 = sum([self.inputs[i]* self.weights[i] for i in range(N) ])\n",
    "        activation = (y1  + self.A) \n",
    "        #print (self.C,\"activate    \", self.weights, self.A, \":\", self.inputs,\"==>\", activation)\n",
    "        return activation\n",
    "    \n",
    "    def transfer(self,activation):\n",
    "        self.output = 1.0 / (1.0 + exp(-activation)) \n",
    "        #print (self.C,\"transfer    \", activation,\"==>\", self.output)\n",
    "        return self.output\n",
    "\n",
    "    def transfer_derivative(self):\n",
    "        return self.output * (1.0 - self.output)\n",
    "\n",
    "    # Calculate the derivative of the activation function\n",
    "    def activation_derivate_by_input(self, idx):\n",
    "        return self.weights[idx]\n",
    "\n",
    "    def activation_derivate_by_weight(self, idx):\n",
    "        return  self.inputs[idx]\n",
    "\n",
    "    def activation_derivate_by_A(self):\n",
    "        return 1\n",
    "    \n",
    "    def print_neuron_param(self):\n",
    "        print(self.weights, self.A, self.C,\":\",self.inputs, self.output)\n",
    "\n",
    "    def calculate_update(self, Ct, m_st):\n",
    "        #print (self.C,\"calc_delta    \",self.dw, self.dA ,\"==>\", )\n",
    "        for j in range(len(self.weights)):\n",
    "            self.dw[j] += self.delta * self.activation_derivate_by_weight(j)\n",
    "        self.dA +=  self.delta*self.activation_derivate_by_A()\n",
    "        #print (self.C,\"          ==>\",self.dw, self.dA  )\n",
    "\n",
    "        \n",
    "    def update_weights_adam(self, l_rate, t):\n",
    "        for j in range(len(self.weights)):\n",
    "            self.m_dw[j] = self.beta1*self.m_dw[j] + (1-self.beta1)*self.dw[j]\n",
    "        # *** biases *** #\n",
    "        self.m_dA = self.beta1*self.m_dA + (1-self.beta1)*self.dA\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** weights *** #\n",
    "        for j in range(len(self.weights)):\n",
    "            self.v_dw[j] = self.beta2*self.v_dw[j] + (1-self.beta2)*(self.dw[j]**2)\n",
    "        # *** biases *** #\n",
    "        self.v_dA = self.beta2*self.v_dA + (1-self.beta2)*(self.dA**2)\n",
    "\n",
    "        ## bias correction\n",
    "        m_dw_corr = [0 for _ in range(len(self.weights))] \n",
    "        v_dw_corr = [0 for _ in range(len(self.weights))] \n",
    "        for j in range(len(self.weights)):\n",
    "                m_dw_corr[j] = self.m_dw[j]/(1-self.beta1**t)\n",
    "        m_dA_corr = self.m_dA/(1-self.beta1**t)\n",
    "        for j in range(len(self.weights)):\n",
    "            v_dw_corr[j] = self.v_dw[j]/(1-self.beta2**t)\n",
    "        v_dA_corr = self.v_dA/(1-self.beta2**t)\n",
    "        \n",
    "        for j in range(len(self.weights)):\n",
    "            self.weights[j] -= self.eta*(m_dw_corr[j]/(np.sqrt(v_dw_corr[j])+self.epsilon))\n",
    "        self.A -= self.eta*(m_dA_corr/(np.sqrt(v_dA_corr)+self.epsilon))\n",
    "        \n",
    "        #s1 = sqrt(sum([x**2 for x in self.weights]))\n",
    "        #self.weights = [x / s1 for x in self.weights]\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dA = 0\n",
    "        \n",
    "    def update_weights(self, l_rate):\n",
    "        #print (self.C,\"update    \", self.weights,self.A)\n",
    "        for j in range(len(self.weights)):\n",
    "            self.weights[j] -=  l_rate * self.dw[j]\n",
    "        self.A -= l_rate * self.dA\n",
    "        #print (self.C,\"        ==>\", self.weights,self.A)\n",
    "\n",
    "        #s1 = sqrt(sum([x**2 for x in self.weights]))\n",
    "        #self.weights = [x / s1 for x in self.weights]\n",
    "        \n",
    "        self.dw = [0 for _ in range(len(self.weights))]\n",
    "        self.dA = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "class SSNN_network():\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.layers = []\n",
    "        self.HL = 0\n",
    "        self.OL = 0\n",
    "        self.outputs = []\n",
    "        self.tr_stat = [-1]\n",
    "\n",
    "    def init (self, n_inputs, hidden_nmode, outputs_nmode):\n",
    "        self.layers = []\n",
    "        n_outputs = len(outputs_nmode)\n",
    "        n_hiddens = len(hidden_nmode)\n",
    "        self.outputs = [outputs_nmode[i][1] for i in range(len(outputs_nmode))]\n",
    "        self.HL = -1\n",
    "        self.OL = 0\n",
    "        self.layers.append([])\n",
    "        if n_hiddens > 0:\n",
    "            self.layers.append([])\n",
    "            self.HL = 0\n",
    "            self.OL = 1\n",
    "            for i in range(n_hiddens):\n",
    "                if hidden_nmode[i][0] == 'S': \n",
    "                    self.layers[self.HL].append(neuron_s(n_inputs,hidden_nmode[i][1],False))\n",
    "                else:\n",
    "                    self.layers[self.HL].append(neuron_l(n_inputs,hidden_nmode[i][1],False))\n",
    "            for i in range(n_outputs):\n",
    "                if outputs_nmode[i][0] == 'S': \n",
    "                    self.layers[self.OL].append(neuron_s(n_hiddens,outputs_nmode[i][1],True))\n",
    "                else:\n",
    "                    self.layers[self.OL].append(neuron_l(n_hiddens,outputs_nmode[i][1],True))\n",
    "        else:\n",
    "            for i in range(n_outputs):\n",
    "                if outputs_nmode[i][0] == 'S': \n",
    "                    self.layers[self.OL].append(neuron_s(n_inputs,outputs_nmode[i][1],True))\n",
    "                else:\n",
    "                    self.layers[self.OL].append(neuron_l(n_inputs,outputs_nmode[i][1],True))\n",
    "                    \n",
    "    def init_B (self, n_inputs, n_hiddens_S,n_hiddens_L, n_outputs_S,n_outputs_L):\n",
    "        self.layers = []\n",
    "        self.outputs = [i for i in range(n_outputs_S +n_outputs_L )]\n",
    "        self.HL = -1\n",
    "        self.OL = 0\n",
    "        n_hiddens = n_hiddens_S + n_hiddens_L\n",
    "        self.layers.append([])\n",
    "        if n_hiddens > 0:\n",
    "            self.layers.append([])\n",
    "            self.HL = 0\n",
    "            self.OL = 1\n",
    "            for i in range(n_hiddens_S):\n",
    "                self.layers[self.HL].append(neuron_s(n_inputs,-1,False))\n",
    "            for i in range(n_hiddens_L):\n",
    "                self.layers[self.HL].append(neuron_l(n_inputs,-1,False))\n",
    "            for i in range(n_outputs_S):\n",
    "                self.layers[self.OL].append(neuron_s(n_hiddens,i,True))\n",
    "            for i in range(n_outputs_L):\n",
    "                self.layers[self.OL].append(neuron_l(n_hiddens,i,True))\n",
    "        else:\n",
    "            for i in range(n_outputs_S):\n",
    "                self.layers[self.OL].append(neuron_s(n_hiddens,i,True))\n",
    "            for i in range(n_outputs_L):\n",
    "                self.layers[self.OL].append(neuron_l(n_hiddens,i,True))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    def copy(self):\n",
    "        new_network = SSNN_network()\n",
    "        new_network.outputs = self.outputs.copy()\n",
    "        new_network.HL = self.HL\n",
    "        new_network.OL = self.OL\n",
    "        new_network.HL = self.HL\n",
    "        for i in range(len(self.layers)):\n",
    "            new_network.layers.append([])            \n",
    "            for neuron in self.layers[i]:\n",
    "                new_network.layers[i].append(neuron.copy())\n",
    "        return new_network\n",
    "        \n",
    "    def forward_propagate(self, row):\n",
    "        for neuron in self.layers[0]:\n",
    "            for i in range(len(neuron.inputs)):\n",
    "                neuron.inputs[i] = row[i]\n",
    "\n",
    "        m_status = False \n",
    "                \n",
    "        for l in range(len(self.layers)):\n",
    "            layer = self.layers[l]\n",
    "            for neuron in layer:\n",
    "                activation = neuron.activate()\n",
    "                neuron.transfer(activation)\n",
    "                if neuron.mode == 'C':\n",
    "                    if neuron.output > .5 and neuron.C == row[-1]:\n",
    "                        m_status = True\n",
    "            if l < self.OL:\n",
    "                for neuron in self.layers[l+1]:\n",
    "                    for i in range(len(self.layers[l])):\n",
    "                        neuron2 = self.layers[l][i]\n",
    "                        neuron.inputs[i] = neuron2.output\n",
    "\n",
    "        outputs = []\n",
    "        for neuron in self.layers[self.OL]:\n",
    "            outputs.append(neuron.output)\n",
    "        return (outputs, m_status)\n",
    "     \n",
    "    \n",
    "    def backward_propagate_error(self, expected):\n",
    "        for lv in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[lv]\n",
    "            if lv != self.OL:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    error = 0.0\n",
    "                    for q in range(len(self.layers[lv + 1])):\n",
    "                        neuron_out = self.layers[lv + 1][q]\n",
    "                        error += (neuron_out.activation_derivate_by_input(j) * neuron_out.delta)\n",
    "                    \n",
    "                    neuron.delta = error * neuron.transfer_derivative()\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    neuron.delta = -(expected[j] - neuron.output) * neuron.transfer_derivative()\n",
    "                #print(\"prop error\",neuron.delta, errors[j] , neuron.transfer_derivative())\n",
    "                \n",
    "    def test_update_weights(self, l_rate, train):\n",
    "        #print (\"Update weights test\")\n",
    "        acc = self.test_network(train)\n",
    "        err = self.get_error(train)\n",
    "        X = [0]\n",
    "        YE = [err]\n",
    "        YA = [acc]\n",
    "        #print (\"base:\",acc,err)\n",
    "        for l in [0.1 + 0.1*x for x in range(20)]:\n",
    "            networks = self.copy()\n",
    "            networks.update_weights(l)\n",
    "            acc = networks.test_network(train)\n",
    "            err = networks.get_error(train)\n",
    "            #print (l,\":\",acc,err)\n",
    "            X.append(l)\n",
    "            YE.append(err)\n",
    "            YA.append(acc)\n",
    "\n",
    "        plt.plot(X,YE)\n",
    "        plt.show()\n",
    "        plt.plot(X,YA)\n",
    "        plt.show()\n",
    "                \n",
    "            \n",
    "    def get_error(self, train):\n",
    "        train = self.normalize(train) \n",
    "        sum_error = 0\n",
    "        n_outputs = len(self.outputs)\n",
    "        for row in train:\n",
    "            voutputs = self.forward_propagate( row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            for i in range(n_outputs):\n",
    "                if self.outputs[i] == row[-1]:\n",
    "                    expected[i] = 1\n",
    "            sum_error += sum([(expected[i]-voutputs[i])**2 for i in range(len(expected))])\n",
    "        return sum_error\n",
    "\n",
    "    def test_network(self, test):\n",
    "        train = self.normalize(test)\n",
    "        n_outputs = len(self.outputs)\n",
    "        dbok = 0\n",
    "        self.tr_stat = [0 for _ in range(len(test))]\n",
    "        #print(\"test\")\n",
    "        for i in range(len(test)):\n",
    "            row = train[i]\n",
    "            (voutputs,_) = self.forward_propagate( row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            idx = voutputs.index(max(voutputs))\n",
    "            if self.outputs[idx] == row[-1]:\n",
    "                dbok += 1\n",
    "                self.tr_stat[i] = 1\n",
    "            #print (row, voutputs, self.tr_stat[i])\n",
    "        #print (\"accuray:\", dbok / len(train))\n",
    "        return dbok / len(test)\n",
    "    \n",
    "    def calculate_update(self, C, m_st):\n",
    "        for i in range(len(self.layers)):\n",
    "            for neuron in self.layers[i]:\n",
    "                neuron.calculate_update(C, m_st);\n",
    "    \n",
    "    def update_weights(self, l_rate, t):\n",
    "        for i in range(len(self.layers)):\n",
    "            for neuron in self.layers[i]:\n",
    "                neuron.update_weights_adam(l_rate,t);\n",
    "                #neuron.update_weights(l_rate);\n",
    "                \n",
    "                \n",
    "    def init_ss_neurons(self, train):\n",
    "        C = len(self.outputs)\n",
    "        CD = dict()\n",
    "        for c in range(C):\n",
    "            CD[c] = []\n",
    "            \n",
    "        for r in range(len(train)):\n",
    "            row = train[r]\n",
    "            CD[row[-1]].append(r)\n",
    "            \n",
    "        sdb = 0\n",
    "        for neuron in self.layers[0]:\n",
    "            if neuron.mode == 'C':\n",
    "                sdb = sdb + 1\n",
    "                    \n",
    "        c = 0\n",
    "        for neuron in self.layers[0]:\n",
    "            if neuron.mode == 'C':\n",
    "                if neuron.C < 0:\n",
    "                    if c < C:                    \n",
    "                        neuron.C = c\n",
    "                        p = sample(range(len(CD[c])),1)[0]\n",
    "                        r = CD[c][p]\n",
    "                        for i in range(len(neuron.weights)):\n",
    "                            neuron.weights[i] = train[r][i]\n",
    "                        neuron.R = .05 + 0.15*random()\n",
    "                    else:\n",
    "                        r = sample(range(len(train)),1)[0]\n",
    "                        neuron.C = train[r][-1]\n",
    "                        for i in range(len(neuron.weights)):\n",
    "                            neuron.weights[i] = train[r][i]\n",
    "                        neuron.R = .05 + 0.15*random()\n",
    "                    c = c + 1\n",
    "                else:                    \n",
    "                    p = sample(range(len(CD[neuron.C])),1)[0]\n",
    "                    r = CD[neuron.C][p]\n",
    "                    for i in range(len(neuron.weights)):\n",
    "                        neuron.weights[i] = train[r][i]\n",
    "                    neuron.R = .05 + 0.15*random()\n",
    "                    \n",
    "\n",
    "    def train_network(self, train,test, l_rate, n_epoch, drf = 5):\n",
    "        train = self.normalize(train)\n",
    "        errorlist = []\n",
    "        n_outputs = len(self.outputs)\n",
    "        self.init_ss_neurons(train)\n",
    "        #print (\"INDULO -----------------------------------------------------------\")\n",
    "        acc = self.test_network (test)\n",
    "        print (\"init acc:\", acc)\n",
    "        #print (\"-----------------------------------------------------------\")\n",
    "        min_error = 100000000\n",
    "        t = 1\n",
    "        for epoch in range(n_epoch):\n",
    "            sum_error = 0\n",
    "            for row in train:\n",
    "                                     \n",
    "                #print (\"forward_propagate -----------------\", row)\n",
    "                (voutputs, cst)  = self.forward_propagate( row)\n",
    "                \n",
    "                expected = [0 for i in range(n_outputs)]\n",
    "                for i in range(n_outputs):\n",
    "                    if self.outputs[i] == row[-1]:\n",
    "                        expected[i] = 1\n",
    "                sum_error += sum([(expected[i]-voutputs[i])**2 for i in range(len(expected))])\n",
    "                \n",
    "                #print (\"backward_propagate -----------------\", expected)\n",
    "                self.backward_propagate_error( expected)\n",
    "                \n",
    "                #if random() < 0.1:\n",
    "                #    self.test_update_weights(l_rate,train)\n",
    "\n",
    "                #print (\"calculate update -----------------\", cst)\n",
    "                self.calculate_update(row[-1], cst)\n",
    "                \n",
    "            #print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "            \n",
    "            errorlist.append(sum_error)\n",
    "            if sum_error < min_error:\n",
    "                min_error = sum_error\n",
    "                winner_network = network.copy()\n",
    "                \n",
    "            #if epoch % drf == 0:\n",
    "            #print (\"update weights -----------------------------------\")\n",
    "            self.update_weights(l_rate, t)\n",
    "            t = t + 1\n",
    "            \n",
    "            #self.draw_network( train)\n",
    "            #self.print_network_param()\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            (voutputs, _) = self.forward_propagate( row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            for i in range(n_outputs):\n",
    "                if self.outputs[i] == row[-1]:\n",
    "                    expected[i] = 1\n",
    "            sum_error += sum([(expected[i]-voutputs[i])**2 for i in range(len(expected))])\n",
    "        #print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "        if sum_error < min_error:\n",
    "            min_error = sum_error\n",
    "            winner_network = network.copy()\n",
    "        \n",
    "        #print (\"ZARO -----------------------------------------------------------\")\n",
    "        acc = winner_network.test_network (test)\n",
    "        #print (\"----------------------------------------------------------------\")\n",
    "        print (\"min error:\", min_error)\n",
    "        print (\"accuracy:\",acc)\n",
    "        plt.plot( [ i for i in range(len(errorlist))], errorlist) \n",
    "        plt.show()\n",
    "        acc2 = network.test_network (test)\n",
    "        print (\"accuracy2:\",acc2)\n",
    "        return winner_network\n",
    "            \n",
    "                \n",
    "    def print_network_param(self):\n",
    "        for layer in self.layers:\n",
    "            print (\"Layer ---------------\")\n",
    "            for neuron in layer:\n",
    "                neuron.print_neuron_param()\n",
    "            \n",
    "    def normalize (self, train):\n",
    "        mx = []\n",
    "        mn = []\n",
    "        for i in range(len(train[0])-1):\n",
    "            mx.append(max([x[i] for x in train ]))\n",
    "            mn.append(min([x[i] for x in train ]))\n",
    "        for row in train:\n",
    "            for i in range(len(row)-1):\n",
    "                row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "        return train\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 0, 4, 1, 4, 1, 4, 2, 4, 2, 4, 1, 4, 0, 0, 3, 2, 2, 1, 2, 4, 2, 0, 4, 1, 3, 3, 4, 0, 4, 4, 4, 1, 2, 3, 0, 1, 1, 1, 2, 1, 1, 0, 4, 0, 2, 3, 4, 3, 0, 2, 1, 1, 0, 3, 0, 0, 4, 0, 0, 3, 4, 3, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 3, 0, 4, 1, 4, 0, 1, 1, 2, 2, 2, 3, 0, 1, 2, 3, 4, 1, 3, 4, 3, 3, 1, 3, 4, 1]\n",
      "init acc: 0.26262626262626265\n",
      "min error: 631.2938254707898\n",
      "accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy2: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def gen_cluster_data(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "    print(cmap)\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "\n",
    "C = 5\n",
    "M = 4\n",
    "(T1,T2)  = gen_cluster_data(C, 100, 1000, M)\n",
    "\n",
    "network = SSNN_network()\n",
    "network.init_B(M,2*C,2*C ,0,C)\n",
    "opt_nw = network.train_network( T1, T2, .02, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
