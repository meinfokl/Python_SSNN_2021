{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "empirical-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90179956 0.9417195  0.37377474 0.07043936 0.53236914 0.7381097 ]\n",
      " [0.5166569  0.40206912 0.8782092  0.26794338 0.8631228  0.28210485]]\n",
      "pontossag: 0.20733333333333334 3567\n",
      "Epoch 1, Loss: 1.7276667356491089, Accuracy: 21.866666793823242, Test Accuracy: 21.843687057495117\n",
      "Epoch 2, Loss: 1.616129994392395, Accuracy: 29.244443893432617, Test Accuracy: 31.663326263427734\n",
      "Epoch 3, Loss: 1.5102492570877075, Accuracy: 37.06666564941406, Test Accuracy: 39.078155517578125\n",
      "Epoch 4, Loss: 1.436051845550537, Accuracy: 42.511112213134766, Test Accuracy: 44.288578033447266\n",
      "Epoch 5, Loss: 1.3718845844268799, Accuracy: 47.42222213745117, Test Accuracy: 47.69538879394531\n",
      "pontossag: 0.5202222222222223 2159\n",
      "Epoch 6, Loss: 1.3138889074325562, Accuracy: 50.488887786865234, Test Accuracy: 50.30060577392578\n",
      "Epoch 7, Loss: 1.2604364156723022, Accuracy: 54.31110763549805, Test Accuracy: 54.909820556640625\n",
      "Epoch 8, Loss: 1.212226152420044, Accuracy: 56.266666412353516, Test Accuracy: 56.312625885009766\n",
      "Epoch 9, Loss: 1.1682754755020142, Accuracy: 57.5111083984375, Test Accuracy: 57.71543502807617\n",
      "Epoch 10, Loss: 1.1274458169937134, Accuracy: 58.68889236450195, Test Accuracy: 59.31863784790039\n",
      "pontossag: 0.6342222222222222 1646\n",
      "Epoch 11, Loss: 1.0885322093963623, Accuracy: 60.577781677246094, Test Accuracy: 62.92584991455078\n",
      "Epoch 12, Loss: 1.0521403551101685, Accuracy: 62.95555877685547, Test Accuracy: 64.12825775146484\n",
      "Epoch 13, Loss: 1.0179352760314941, Accuracy: 65.17778015136719, Test Accuracy: 65.53106689453125\n",
      "Epoch 14, Loss: 0.985532283782959, Accuracy: 67.37777709960938, Test Accuracy: 66.93386840820312\n",
      "Epoch 15, Loss: 0.9547858238220215, Accuracy: 68.66666412353516, Test Accuracy: 67.33467102050781\n",
      "pontossag: 0.7013333333333334 1344\n",
      "Epoch 16, Loss: 0.9253512024879456, Accuracy: 69.75555419921875, Test Accuracy: 67.73546600341797\n",
      "Epoch 17, Loss: 0.8972770571708679, Accuracy: 70.04444885253906, Test Accuracy: 67.73546600341797\n",
      "Epoch 18, Loss: 0.8708052039146423, Accuracy: 70.33332824707031, Test Accuracy: 67.93587493896484\n",
      "Epoch 19, Loss: 0.8457266688346863, Accuracy: 70.4888916015625, Test Accuracy: 67.73546600341797\n",
      "Epoch 20, Loss: 0.8217998147010803, Accuracy: 70.93333435058594, Test Accuracy: 68.13627624511719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x257023350f0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hybrid model L_S \n",
    "\n",
    "# P 05\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import relu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LSLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,  num_outputs_s, num_outputs_l, activation=sigmoid, wstd = 0.3, bstd = 0.5):\n",
    "        super(LSLayer, self).__init__()\n",
    "        self.num_outputs_l = num_outputs_l\n",
    "        self.num_outputs_s = num_outputs_s\n",
    "        self.num_outputs = num_outputs_l + num_outputs_s\n",
    "        self.activation = activation\n",
    "        self.wstd = wstd\n",
    "        self.bstd = bstd\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=(int(input_shape[-1]),\n",
    "                                             self.num_outputs), \n",
    "                                      initializer=tf.keras.initializers.RandomNormal(stddev=self.wstd),\n",
    "                                     trainable=True)\n",
    "        \n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                      shape=[self.num_outputs],\n",
    "                                    initializer=tf.keras.initializers.RandomNormal(stddev=self.bstd),\n",
    "                                   trainable=True)\n",
    "\n",
    "    \n",
    "    # F2 method LS layer\n",
    "    def call(self, input):\n",
    "        \n",
    "        isp = input.shape\n",
    "        In1 = tf.transpose(input)\n",
    "        kernel_S, kernel_L  = tf.split(self.kernel,[ self.num_outputs_s, self.num_outputs_l ], axis = 1 )\n",
    "        bias_S, bias_L  = tf.split(self.bias,[ self.num_outputs_s, self.num_outputs_l ], axis = 0 )\n",
    "        \n",
    "        # case spherical\n",
    "        \n",
    "        s_shape  = self.num_outputs_s\n",
    "        In2 = tf.stack([In1] * s_shape)\n",
    "        InD = tf.transpose(In2)\n",
    "        WD = tf.stack([kernel_S] * isp[0])\n",
    "        ddd = WD - InD\n",
    "        dd0 = tf.math.multiply(ddd, ddd)\n",
    "        dd1 = tf.math.reduce_sum(dd0, axis =1)\n",
    "        dd2 = tf.cast(dd1,tf.double)\n",
    "        dd3 = tf.sqrt(dd2)\n",
    "        d_r = tf.cast(dd3,tf.float32)\n",
    "        d_R = tf.abs(bias_S)\n",
    "        d_rR = tf.math.divide_no_nan(d_r,d_R)\n",
    "        d_x0 = tf.ones(d_rR.shape) - d_rR\n",
    "        result_S = tf.math.scalar_mul(6,d_x0)\n",
    "        result_S = sigmoid(result_S)\n",
    "        \n",
    "        # case linear\n",
    "        \n",
    "        d_1 = tf.stack([bias_L] * isp[0])\n",
    "        result_L = tf.matmul(input, kernel_L) + d_1 \n",
    "        result_L = relu(result_L)\n",
    "        \n",
    "        # merge\n",
    "        \n",
    "        result = tf.concat([result_S, result_L],axis=1)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "class NN_Model(Model):\n",
    "    \n",
    "    def __init__(self,c,l,n,m,hs,hl):\n",
    "        self.C=c\n",
    "        self.L=l\n",
    "        self.N=n\n",
    "        self.M=m\n",
    "        self.HS = hs\n",
    "        self.HL = hl\n",
    "        super(NN_Model, self).__init__()\n",
    "        self.d1 = LSLayer(self.HS,self.HL)\n",
    "        self.d2 = Dense(self.C)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        #print (\"call benn:\",x, tf.math.reduce_sum(x))\n",
    "        return self.d2(x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(datas, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(datas, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    \n",
    "    predictions = model(datas, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "C= 6\n",
    "L= 50\n",
    "N= 5000\n",
    "M= 6\n",
    "HS = 15\n",
    "HL = 15\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NN_Model(C,L,N,M,HS,HL)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "(x_train,y_train,x_test,y_test) = gen_data_array(C, L, N, M)\n",
    "print (x_train[:2])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(32)\n",
    "#print (train_ds)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "    \n",
    "EPOCHS = 20\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for datas, labels in train_ds:\n",
    "        train_step(datas, labels)\n",
    "        \n",
    "                \n",
    "    for test_datas, test_labels in test_ds:\n",
    "        #print (\"test_data_shape\", test_datas.shape)\n",
    "        predictions = model(test_datas, training=False)\n",
    "        #print (\"ttttttttttttttttttt\")\n",
    "        #for i in range(test_datas.shape[0]):\n",
    "        #    print (predictions.numpy()[i], test_labels.numpy()[i])\n",
    "        test_step(test_datas, test_labels)\n",
    "    \n",
    "    X.append(epoch)\n",
    "    Y.append(test_accuracy.result() * 100)\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "      )    \n",
    "\n",
    "plt.plot(X, Y,label=\"Accuracy curve\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "spiritual-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.4 6.719788356455548\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\n",
    "x = [70,70,61,76,59,76,66,76,79,71]\n",
    "print (sum(x)/len(x), statistics.stdev(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "understood-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "def gen_cluster_data_list(Cv, Lv, Nv, Mv):\n",
    "    Tr = []\n",
    "    Ts = []\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    X, y = make_blobs(n_samples=N, centers=L, n_features=M,cluster_std=.5, random_state=11)\n",
    "    cmap = []\n",
    "    for _ in range(L):\n",
    "        cmap.append(random.randint(0,C-1))\n",
    "    cols = []\n",
    "    for i in range(N):\n",
    "        cols.append(cmap[y[i]])\n",
    "\n",
    "    for i in range(int(0.9*N)):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Tr.append(row)\n",
    "    \n",
    "    for i in range(int(0.9*N)+1,N):\n",
    "        row = [X[i,j] for j in range(M)]\n",
    "        row.append(cols[i])\n",
    "        Ts.append(row)\n",
    "        \n",
    "    return (Tr, Ts)\n",
    "\n",
    "def normalize (train):\n",
    "    mx = []\n",
    "    mn = []\n",
    "    for i in range(len(train[0])-1):\n",
    "        mx.append(max([x[i] for x in train ]))\n",
    "        mn.append(min([x[i] for x in train ]))\n",
    "    for row in train:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - mn[i]) / (mx[i] - mn[i]) \n",
    "    return train\n",
    "\n",
    "\n",
    "def gen_data_array(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,C))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i,row[-1]] = 1\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,C))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i, row[-1]] = 1\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n",
    "def gen_data_array_s(Cv, Lv, Nv, Mv):\n",
    "    C = Cv  # number of categories\n",
    "    L = Lv   # number of centers\n",
    "    N = Nv  # number of elements\n",
    "    M = Mv  # number of dimensions\n",
    "    (T1,T2)  = gen_cluster_data_list(C, L, N, M)\n",
    "\n",
    "    T = normalize(T1)\n",
    "    N = len(T)\n",
    "    x2_train = np.zeros((N,M),dtype='float32')\n",
    "    y2_train = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        row = T[i]\n",
    "        for j in range(M):\n",
    "            x2_train[i,j] = row[j]\n",
    "        y2_train[i] = row[-1]\n",
    "\n",
    "    Ts = normalize(T2)\n",
    "    Ns = len(Ts)\n",
    "    x2_test = np.zeros((Ns,M),dtype='float32')\n",
    "    y2_test = np.zeros((Ns,1))\n",
    "    for i in range(Ns):\n",
    "        row = Ts[i]\n",
    "        for j in range(M):\n",
    "            x2_test[i,j] = row[j]\n",
    "        y2_test[i] = row[-1]\n",
    "        \n",
    "    return (x2_train,y2_train, x2_test, y2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-branch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
